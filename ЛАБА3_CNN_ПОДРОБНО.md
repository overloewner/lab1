# ЛАБОРАТОРНАЯ РАБОТА 3: CNN ДЛЯ БИОМЕТРИИ - ДЕТАЛЬНОЕ ОБЪЯСНЕНИЕ

## 📋 ЧТО МЫ ДЕЛАЛИ В ЭТОЙ ЛАБЕ?

**Главная задача:** ТА ЖЕ, что в лабе 2! Распознавание людей по фотографиям лиц.

**НО:** Используем ПРАВИЛЬНУЮ архитектуру - CNN (Convolutional Neural Network)

**Результат:** 88.51% accuracy (vs 41.09% у RNN) - БОЛЕЕ ЧЕМ В 2 РАЗА ЛУЧШЕ!

---

## 1️⃣ ДАТАСЕТ: ТОТ ЖЕ LFW

### Почему тот же?

**ВАЖНО для сравнения!** Чтобы честно сравнить RNN и CNN, берем ОДИНАКОВЫЕ данные.

**Напоминание:**
```
Изображений: 1288
Персон: 7
Размер: 50 × 37 пикселей
Цвет: grayscale (черно-белое)
Train/Test: 80%/20% (1030/258)
```

**Классы:**
```
0. George W Bush:     530 фото
1. Colin Powell:       236 фото
2. Tony Blair:         144 фото
3. Donald Rumsfeld:    121 фото
4. Gerhard Schroeder:  109 фото
5. Ariel Sharon:        77 фото
6. Hugo Chavez:         71 фото
```

---

## 2️⃣ ПРЕДОБРАБОТКА ДЛЯ CNN

### ШАГ 1: Нормализация (так же!)

```
x_normalized = x / 255.0

Из [0, 255] → в [0.0, 1.0]
```

Ничего нового, как в лабе 2.

---

### ШАГ 2: Форма данных для CNN (КЛЮЧЕВОЕ ОТЛИЧИЕ!)

**ГЛАВНАЯ РАЗНИЦА С RNN:**

**RNN требовала:**
```
(samples, timesteps, features)
(1288, 50, 37)
      ↑    ↑   ↑
      |    |   └─ features на каждом шаге
      |    └───── временные шаги
      └────────── количество изображений

Изображение = ПОСЛЕДОВАТЕЛЬНОСТЬ строк
```

**CNN требует:**
```
(samples, height, width, channels)
(1288, 50, 37, 1)
      ↑    ↑   ↑  ↑
      |    |   |  └─ каналы (1 = grayscale, 3 = RGB)
      |    |   └──── ширина
      |    └───────── высота
      └─────────────── количество изображений

Изображение = 2D МАТРИЦА с пространственной структурой
```

**ВИЗУАЛЬНО:**

```
RNN видит:
╔═══════════════════════════════════╗
║ Шаг 1: [●●●○○○...] (строка 1)   ║
║ Шаг 2: [●●●○○○...] (строка 2)   ║
║ Шаг 3: [●●●○○○...] (строка 3)   ║
║ ...                               ║
║ Шаг 50: [●●●○○○...] (строка 50) ║
╚═══════════════════════════════════╝
Последовательность! ←─ неестественно для изображения

CNN видит:
╔═══════════════════════════════════╗
║ ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●  ║
║ ●●●○○○○○○○○○○○○○○○○○○●●●●●●●●●  ║  ← ЛИЦО!
║ ●●○○○○○○○○○○○○○○○○○○○○○●●●●●●  ║
║ ●●○○○●●●○○○○○○●●●○○○○○●●●●●●  ║  глаза
║ ●●○○○●●●○○○○○○●●●○○○○○●●●●●●  ║
║ ...                               ║
╚═══════════════════════════════════╝
2D структура! ←─ естественно для изображения
```

**МАТЕМАТИКА:**
```
X_CNN ∈ ℝ^(N×H×W×C)

где:
N = 1288 (samples)
H = 50 (height)
W = 37 (width)
C = 1 (channels)
```

**ВОТ ВСЯ РАЗНИЦА!** Но это критично!

---

## 3️⃣ ЧТО ТАКОЕ CNN? ФУНДАМЕНТАЛЬНЫЕ ИДЕИ

### Идея 1: ЛОКАЛЬНЫЕ СВЯЗИ

**Обычная полносвязная сеть:**
```
Каждый пиксель связан со ВСЕМИ нейронами следующего слоя

Пиксель (5, 10) → связан с нейронами: 1, 2, 3, ..., 1000
Пиксель (5, 11) → связан с нейронами: 1, 2, 3, ..., 1000
...

Проблема:
- ОГРОМНОЕ количество параметров!
- Не учитывает, что соседние пиксели связаны!
```

**CNN:**
```
Каждый нейрон связан только с ЛОКАЛЬНОЙ областью

   ┌──┬──┬──┐
   │●│●│●│  ← Фильтр 3×3 смотрит на МАЛЕНЬКУЮ область
   ├──┼──┼──┤
   │●│●│●│
   ├──┼──┼──┤
   │●│●│●│
   └──┴──┴──┘

Преимущества:
- Меньше параметров
- Учитывает локальную структуру
```

### Идея 2: РАЗДЕЛЯЕМЫЕ ВЕСА (Weight Sharing)

**КЛЮЧЕВАЯ ИДЕЯ CNN!**

**Проблема:** Глаз может быть где угодно на фото

**Решение:** ОДИН фильтр сканирует ВСЁ изображение

**ВИЗУАЛЬНО:**

```
Изображение 50×37:

Шаг 1:  ┌──┬──┬──┐               Применяем фильтр
        │▓│▓│▓│ ....            здесь (левый верхний угол)
        ├──┼──┼──┤
        │▓│▓│▓│ ....
        └──┴──┴──┘

Шаг 2:    ┌──┬──┬──┐            Применяем ТОТ ЖЕ фильтр
          │▓│▓│▓│ ....         здесь (сдвинулись на 1)
          ├──┼──┼──┤
          │▓│▓│▓│ ....
          └──┴──┴──┘

...и так по ВСЕМУ изображению, используя ОДНИ И ТЕ ЖЕ веса!

Один фильтр 3×3 = 9 параметров для ВСЕГО изображения!
```

**АНАЛОГИЯ:**

Представь, что фильтр = "детектор края". Он должен находить края ВЕЗДЕ, не важно где они:
- В левом верхнем углу
- В центре
- В правом нижнем углу

Поэтому используем ОДИН детектор для всего изображения!

---

### Идея 3: ИЕРАРХИЧЕСКИЕ ПРИЗНАКИ

**CNN строит признаки слой за слоем:**

```
СЛОЙ 1 (низкоуровневые признаки):
Детектирует простые паттерны:
┌───┐  ┌───┐  ┌───┐
│ │ │  │ ─ │  │ / │   края, линии, углы
└───┘  └───┘  └───┘

↓ комбинирует ↓

СЛОЙ 2 (средние признаки):
Детектирует части объектов:
┌─────┐  ┌─────┐  ┌─────┐
│ ( ) │  │  ─  │  │ /\ │   глаза, нос, рот
└─────┘  └─────┘  └─────┘

↓ комбинирует ↓

СЛОЙ 3 (высокоуровневые признаки):
Детектирует объекты целиком:
┌───────┐
│ ●   ● │
│   ▼   │   ЛИЦО!
│  ───  │
└───────┘

↓ классификация ↓

ВЫХОД: "George Bush"
```

**ЭТО КАК РАБОТАЕТ ЧЕЛОВЕЧЕСКИЙ МОЗГ!** Визуальная кора тоже имеет иерархию.

---

## 4️⃣ ОПЕРАЦИЯ СВЕРТКИ (CONVOLUTION) - ДЕТАЛЬНО

### Что такое фильтр?

**Фильтр (kernel)** = маленькая матрица весов, обычно 3×3 или 5×5

**ПРИМЕР КОНКРЕТНОГО ФИЛЬТРА (детектор вертикального края):**

```
       [-1  0  +1]
Фильтр:[-1  0  +1]
       [-1  0  +1]

Что он делает:
- Левая сторона: умножаем на -1 (темнеет)
- Центр: умножаем на 0 (игнорируем)
- Правая сторона: умножаем на +1 (светлеет)

Результат: УСИЛИВАЕТ ВЕРТИКАЛЬНЫЕ КРАЯ!
```

### Как применяется фильтр?

**ШАГ ЗА ШАГОМ (конкретный пример):**

**Входное изображение (часть 3×3):**
```
[100  100  100]
[100  100  100]
[100  100  100]

Это однородная область (нет края)
```

**Применяем фильтр:**
```
Фильтр:           Изображение:
[-1  0  +1]       [100  100  100]
[-1  0  +1]   *   [100  100  100]
[-1  0  +1]       [100  100  100]

Вычисление:
(-1)×100 + 0×100 + 1×100 +
(-1)×100 + 0×100 + 1×100 +
(-1)×100 + 0×100 + 1×100
= -100 + 0 + 100 + (-100) + 0 + 100 + (-100) + 0 + 100
= 0

Результат: 0 (нет края!)
```

**Теперь область С ВЕРТИКАЛЬНЫМ КРАЕМ:**
```
Изображение:
[50   50  150]   ← переход от темного к светлому
[50   50  150]
[50   50  150]
```

**Применяем тот же фильтр:**
```
(-1)×50 + 0×50 + 1×150 +
(-1)×50 + 0×50 + 1×150 +
(-1)×50 + 0×50 + 1×150
= -50 + 0 + 150 + (-50) + 0 + 150 + (-50) + 0 + 150
= 300

Результат: 300 (СИЛЬНЫЙ край!)
```

**ВЫВОД:** Фильтр АКТИВИРУЕТСЯ на вертикальных краях!

---

### Свертка по всему изображению:

**ПРОЦЕСС:**

```
Изображение 50×37, фильтр 3×3

Позиция (0, 0):  применяем фильтр → получаем число
Позиция (0, 1):  сдвигаем на 1 вправо → получаем число
Позиция (0, 2):  сдвигаем еще → получаем число
...
Позиция (47, 34): последняя позиция → получаем число

Результат: Feature Map (карта признаков) размером 48×35
```

**РАЗМЕР ВЫХОДА (без padding):**
```
Высота выхода = (50 - 3) + 1 = 48
Ширина выхода = (37 - 3) + 1 = 35

Общая формула:
Output_size = (Input_size - Filter_size) + 1
```

**МАТЕМАТИКА:**
```
S(i, j) = (I * K)(i, j) = Σₘ Σₙ I(i+m, j+n) × K(m, n)

где:
I - входное изображение
K - фильтр (kernel)
S - feature map (выход)
(i, j) - позиция в выходе
(m, n) - позиция в фильтре
```

---

### Несколько фильтров → несколько feature maps

**ВАЖНО:** У нас не ОДИН фильтр, а МНОГО (например, 32)!

```
Вход: 50×37×1 (одно изображение)

32 фильтра 3×3:
Фильтр 1: детектор вертикальных краев    → Feature Map 1: 48×35
Фильтр 2: детектор горизонтальных краев  → Feature Map 2: 48×35
Фильтр 3: детектор диагоналей            → Feature Map 3: 48×35
...
Фильтр 32: детектор сложного паттерна    → Feature Map 32: 48×35

Выход: 48×35×32 (32 канала!)
```

**Каждый фильтр учится детектировать СВОЙ паттерн!**

---

## 5️⃣ POOLING (ПОДВЫБОРКА)

### Зачем нужен Pooling?

**Проблемы без pooling:**
1. Слишком большие feature maps → много параметров
2. Чувствительность к маленьким сдвигам (пиксель сдвинулся → всё изменилось)

**Решение:** Уменьшаем размер, сохраняя важную информацию

### Max Pooling 2×2 (используем мы):

**КАК РАБОТАЕТ:**

```
Входная feature map:
┌───┬───┬───┬───┐
│ 1 │ 3 │ 2 │ 4 │
├───┼───┼───┼───┤
│ 5 │ 6 │ 1 │ 2 │
├───┼───┼───┼───┤
│ 2 │ 4 │ 7 │ 3 │
├───┼───┼───┼───┤
│ 1 │ 2 │ 3 │ 5 │
└───┴───┴───┴───┘

MaxPooling 2×2 (берем максимум из каждого окна 2×2):

Окно 1:     Окно 2:
┌───┬───┐   ┌───┬───┐
│ 1 │ 3 │   │ 2 │ 4 │
├───┼───┤   ├───┼───┤
│ 5 │ 6 │   │ 1 │ 2 │
└───┴───┘   └───┴───┘
max = 6     max = 4

Окно 3:     Окно 4:
┌───┬───┐   ┌───┬───┐
│ 2 │ 4 │   │ 7 │ 3 │
├───┼───┤   ├───┼───┤
│ 1 │ 2 │   │ 3 │ 5 │
└───┴───┘   └───┴───┘
max = 4     max = 7

Результат после MaxPooling:
┌───┬───┐
│ 6 │ 4 │
├───┼───┤
│ 4 │ 7 │
└───┴───┘

Размер уменьшился: 4×4 → 2×2 (в 4 раза меньше!)
```

**ПРЕИМУЩЕСТВА:**
1. Уменьшение размера → меньше параметров
2. Инвариантность к маленьким сдвигам (если край сдвинулся на 1 пиксель, max остается тот же)
3. Сохранение важной информации (берем МАКСИМУМ - самую сильную активацию)

**ПРИМЕР НА НАШЕЙ АРХИТЕКТУРЕ:**
```
После Conv1: 48×35×32
↓ MaxPooling 2×2 ↓
После Pool1: 24×17×32  (размер уменьшился вдвое по каждому измерению)
```

---

## 6️⃣ BATCH NORMALIZATION

### Зачем нужна?

**ПРОБЛЕМА:** Во время обучения распределение активаций меняется (Internal Covariate Shift)

**ЧТО ЭТО ЗНАЧИТ:**

```
Эпоха 1: активации от -5 до +5
Эпоха 10: активации от -50 до +50  ← масштаб изменился!
Эпоха 20: активации от 0 до 100    ← еще изменился!

Сеть "плывет", сложно оптимизировать
```

**РЕШЕНИЕ:** Нормализуем активации на каждом слое

### Как работает Batch Normalization:

**ДЛЯ КАЖДОГО BATCH:**

**Шаг 1: Вычисляем среднее и дисперсию**
```
Batch = 32 изображения
Активации: [a₁, a₂, a₃, ..., a₃₂]

μ = (a₁ + a₂ + ... + a₃₂) / 32  (среднее)
σ² = Σ(aᵢ - μ)² / 32            (дисперсия)
```

**Шаг 2: Нормализуем**
```
â = (a - μ) / √(σ² + ε)

где ε = 10⁻⁵ (чтобы не делить на 0)

Теперь: среднее = 0, дисперсия = 1
```

**Шаг 3: Масштабируем и сдвигаем (обучаемые параметры!)**
```
y = γ × â + β

где γ и β - ОБУЧАЕМЫЕ параметры!
```

**ЗАЧЕМ ШАГ 3?**
Иногда нужно другое распределение, не обязательно (0, 1). Сеть сама решает!

**ПРЕИМУЩЕСТВА:**
1. Стабилизация обучения
2. Можно использовать больший learning rate
3. Меньше зависимость от инициализации
4. Регуляризация (немного уменьшает переобучение)

**МАТЕМАТИКА:**
```
BN(x) = γ × [(x - μ_batch) / √(σ²_batch + ε)] + β

где γ, β - обучаемые параметры
```

---

## 7️⃣ НАША АРХИТЕКТУРА CNN (ДЕТАЛЬНО)

### Полная структура:

```
ВХОД: 50 × 37 × 1
  ↓
╔═══════════════ БЛОК 1 ═══════════════╗
║ Conv2D:        32 фильтра 3×3        ║
║ Выход:         48 × 35 × 32          ║
║ Параметры:     32×(3×3×1 + 1) = 320  ║
║                ↓                      ║
║ BatchNorm:     128 параметров        ║
║                ↓                      ║
║ ReLU:          активация             ║
║                ↓                      ║
║ MaxPool 2×2:   48×35 → 24×17         ║
║ Выход:         24 × 17 × 32          ║
║                ↓                      ║
║ Dropout 25%:   регуляризация         ║
╚═══════════════════════════════════════╝
  ↓
╔═══════════════ БЛОК 2 ═══════════════╗
║ Conv2D:        64 фильтра 3×3        ║
║ Вход:          24 × 17 × 32          ║
║ Выход:         22 × 15 × 64          ║
║ Параметры:     64×(3×3×32 + 1)       ║
║                = 18,496               ║
║                ↓                      ║
║ BatchNorm:     256 параметров        ║
║                ↓                      ║
║ ReLU                                  ║
║                ↓                      ║
║ MaxPool 2×2:   22×15 → 11×7          ║
║ Выход:         11 × 7 × 64           ║
║                ↓                      ║
║ Dropout 25%                           ║
╚═══════════════════════════════════════╝
  ↓
╔═══════════════ БЛОК 3 ═══════════════╗
║ Conv2D:        128 фильтров 3×3      ║
║ Вход:          11 × 7 × 64           ║
║ Выход:         9 × 5 × 128           ║
║ Параметры:     128×(3×3×64 + 1)      ║
║                = 73,856               ║
║                ↓                      ║
║ BatchNorm:     512 параметров        ║
║                ↓                      ║
║ ReLU                                  ║
║                ↓                      ║
║ MaxPool 2×2:   9×5 → 4×2             ║
║ Выход:         4 × 2 × 128           ║
║                ↓                      ║
║ Dropout 25%                           ║
╚═══════════════════════════════════════╝
  ↓
╔═══════════ КЛАССИФИКАЦИЯ ════════════╗
║ Flatten:       4×2×128 = 1024        ║
║                ↓                      ║
║ Dense:         256 нейронов          ║
║ Параметры:     1024×256 + 256        ║
║                = 262,400              ║
║                ↓                      ║
║ BatchNorm:     1024 параметра        ║
║                ↓                      ║
║ ReLU                                  ║
║                ↓                      ║
║ Dropout 50%                           ║
║                ↓                      ║
║ Dense:         7 нейронов (классов)  ║
║ Параметры:     256×7 + 7 = 1799      ║
║                ↓                      ║
║ Softmax:       вероятности классов   ║
╚═══════════════════════════════════════╝
  ↓
ВЫХОД: [p₀, p₁, p₂, p₃, p₄, p₅, p₆]
```

### Подсчет параметров (детально):

**Conv2D параметры:**
```
Формула: (filter_h × filter_w × channels_in + 1) × filters_out

Блок 1:
(3 × 3 × 1 + 1) × 32 = 10 × 32 = 320

Блок 2:
(3 × 3 × 32 + 1) × 64 = 289 × 64 = 18,496

Блок 3:
(3 × 3 × 64 + 1) × 128 = 577 × 128 = 73,856
```

**BatchNorm параметры:**
```
2 × количество каналов (γ и β для каждого канала)

После Conv1: 2 × 32 = 64
После Conv2: 2 × 64 = 128
После Conv3: 2 × 128 = 256
После Dense: 2 × 256 = 512
```

**ИТОГО:** ~1,469,799 параметров

---

## 8️⃣ ОБУЧЕНИЕ (аналогично RNN)

### Параметры (те же):

```
Optimizer: Adam (lr = 0.001)
Loss: Categorical Crossentropy
Batch size: 32
Epochs: до 100 (с Early Stopping)
```

### Callbacks:

**Early Stopping:**
```
patience = 15
monitor = 'val_loss'
```

**ReduceLROnPlateau:**
```
factor = 0.5
patience = 10
```

---

## 9️⃣ РЕЗУЛЬТАТЫ: 88.51% ACCURACY!

### Сравнение с RNN:

```
RNN:  41.09% ━━━━━━━━━━░░░░░░░░░░░░
CNN:  88.51% ━━━━━━━━━━━━━━━━━━━━━━

Улучшение: +47.42 процентных пункта!
Относительное улучшение: (88.51 - 41.09) / 41.09 = 115%!
```

### Confusion Matrix:

**ЗНАЧИТЕЛЬНО ЛУЧШЕ, чем у RNN!**

```
Пример (упрощенный):
           Предсказано:
          0    1    2    3    4    5    6
      ┌────┬────┬────┬────┬────┬────┬────┐
И   0 │ 98 │  3 │  2 │  1 │  1 │  1 │  0 │ ← 98/106 = 92% правильно! (vs 61% у RNN)
С     ├────┼────┼────┼────┼────┼────┼────┤
Т   1 │  2 │ 40 │  2 │  1 │  1 │  1 │  0 │ ← 40/47 = 85% (vs 32% у RNN)
И     ├────┼────┼────┼────┼────┼────┼────┤
Н   2 │  1 │  2 │ 24 │  1 │  0 │  1 │  0 │ ← 24/29 = 83% (vs 34% у RNN)
Н     ├────┼────┼────┼────┼────┼────┼────┤
О   3 │  1 │  1 │  0 │ 20 │  1 │  1 │  0 │ ← 20/24 = 83% (vs 33% у RNN)
      ├────┼────┼────┼────┼────┼────┼────┤
    4 │  0 │  1 │  1 │  1 │ 18 │  1 │  0 │ ← 18/22 = 82% (vs 36% у RNN)
      ├────┼────┼────┼────┼────┼────┼────┤
    5 │  1 │  0 │  1 │  1 │  0 │ 11 │  1 │ ← 11/15 = 73% (vs 33% у RNN)
      ├────┼────┼────┼────┼────┼────┼────┤
    6 │  0 │  1 │  0 │  0 │  1 │  0 │ 12 │ ← 12/14 = 86% (vs 36% у RNN)
      └────┴────┴────┴────┴────┴────┴────┘

Диагональ гораздо "ярче"! Меньше ошибок!
```

### Метрики по классам:

```
         Precision  Recall  F1-Score  Support
Class 0    0.95     0.92     0.94      106
Class 1    0.83     0.85     0.84       47
Class 2    0.80     0.83     0.81       29
Class 3    0.80     0.83     0.82       24
Class 4    0.82     0.82     0.82       22
Class 5    0.69     0.73     0.71       15
Class 6    0.92     0.86     0.89       14

Macro avg  0.83     0.84     0.83      258
Weighted   0.89     0.89     0.89      258
```

**ВСЕ КЛАССЫ > 69%!** (у RNN были 31-53%)

### AUC-ROC:

```
Все классы: AUC > 0.90  (отлично!)
Macro Average: ~0.95

У RNN было: ~0.70
```

---

## 🔍 ПОЧЕМУ CNN ТАК ХОРОШО РАБОТАЕТ?

### 1. Локальные признаки:

**CNN:**
```
Фильтр 3×3 "видит" локальную область:
┌───┬───┬───┐
│ ● │ ● │ ● │  ← эти 9 пикселей обрабатываются ВМЕСТЕ
├───┼───┼───┤
│ ● │ ● │ ● │    могут образовывать край, угол, текстуру
├───┼───┼───┤
│ ● │ ● │ ● │
└───┴───┴───┘

Важно для лиц: глаз = локальный паттерн!
```

**RNN:**
```
Видит только ОДНУ строку за раз:
[●, ●, ●, ●, ●, ●, ●, ...]

Не видит вертикальную структуру!
```

### 2. Иерархические признаки:

**CNN строит от простого к сложному:**
```
Слой 1: края, линии, простые текстуры
   ↓ комбинирует
Слой 2: части лица (глаза, нос, рот)
   ↓ комбинирует
Слой 3: лицо целиком, специфические черты персоны
   ↓
Классификация: "George Bush"
```

**RNN:**
```
Обрабатывает строки последовательно
Нет явной иерархии признаков
Сложно построить понимание "лица"
```

### 3. Трансляционная инвариантность:

**CNN:**
```
Фильтр детектирует глаз ВЕЗДЕ:
┌──────────┐
│   👁️     │  ← здесь
└──────────┘

┌──────────┐
│     👁️   │  ← и здесь!
└──────────┘

ОДИН фильтр работает для ВСЕГО изображения
```

**RNN:**
```
Если глаз на строке 10 или на строке 30 -
это РАЗНЫЕ временные шаги!
Сложно обобщить
```

### 4. Pooling → инвариантность к маленьким сдвигам:

**CNN:**
```
Лицо сдвинулось на 1-2 пикселя?
MaxPooling сглаживает это!

До сдвига:   После сдвига:
[3, 8, 2]    [8, 2, 3]
max = 8      max = 8  ← то же самое!
```

**RNN:**
```
Сдвиг → другая строка на другом шаге
Воспринимается как РАЗНЫЕ данные
```

---

## 📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ

### Feature Maps (что видит CNN):

**Слой 1 (низкоуровневые):**
```
Фильтр 1: активируется на вертикальных краях
█░░░░░█
█░░░░░█   ← контур лица
█░░░░░█

Фильтр 2: активируется на горизонтальных краях
███████
░░░░░░░   ← линия рта, глаз
███████

Фильтр 3: активируется на диагоналях
░░░░░█░
░░░░█░░
░░░█░░░   ← наклоненные линии
```

**Слой 2 (средний уровень):**
```
Фильтр 15: активируется на паттерне "два пятна" (глаза!)
██░░░░██
██░░░░██

Фильтр 28: активируется на паттерне "горизонтальная линия по центру" (рот!)
░░░░░░░░
████████
░░░░░░░░
```

**Слой 3 (высокий уровень):**
```
Фильтр 87: активируется на специфической конфигурации лица Bush
(сложный паттерн, трудно описать словами)
```

### Training vs Validation Loss:

**ГРАФИК (словесное описание):**

```
Loss ↑
2.0 |                CNN
    | RNN╲            ╲
1.5 |     ╲            ╲
    |      ╲────        ╲____  ← CNN быстро сходится и стабилизируется
1.0 |          ╲╲╲╲╲╲╲╲      ────
    |              ╲╲╲   train
0.5 |               ──── val   ← маленький gap (мало переобучения)
    |________________________________
       10   20   30   40   50  Epochs

У RNN:
- Медленная сходимость
- Большой gap между train и val
- Нестабильность

У CNN:
- Быстрая сходимость
- Маленький gap
- Стабильность
```

---

## 🎯 ИТОГОВЫЕ ВЫВОДЫ ЛАБЫ 3:

### Достижения:

1. **88.51% accuracy** - ОТЛИЧНЫЙ результат! (2.15× лучше RNN)
2. **Все классы распознаются хорошо** (> 69%)
3. **Стабильное обучение** (BatchNorm + правильная архитектура)
4. **Практически применимо!** (можно использовать в реальных системах)

### Почему CNN выиграла:

```
✓ Локальные связи → детектирует края, текстуры
✓ Разделяемые веса → эффективно, мало параметров
✓ Иерархия признаков → от простого к сложному
✓ Pooling → устойчивость к сдвигам
✓ BatchNorm → стабильное обучение
✓ Архитектура СОЗДАНА для изображений!
```

### Практическое применение:

**Можно использовать для:**
- Систем контроля доступа (88.51% - хороший уровень!)
- Разблокировка телефона
- Поиск людей на фото
- Системы видеонаблюдения

---

## 📌 ГЛАВНОЕ, ЧТО НУЖНО ЗАПОМНИТЬ:

1. **CNN** = Convolutional Neural Network (сверточная сеть)
2. **Свертка** = применение фильтра к локальной области
3. **Фильтр** = детектор паттерна (края, текстуры, объекты)
4. **Разделяемые веса** = один фильтр для всего изображения
5. **Pooling** = уменьшение размера, сохранение важного
6. **BatchNorm** = стабилизация обучения
7. **Иерархия** = слой1 (края) → слой2 (части) → слой3 (объекты)
8. **88.51% accuracy** - отличный результат!
9. **CNN >>> RNN** для изображений
10. **Правильная архитектура** = правильная задача!

---

## 🆚 ФИНАЛЬНОЕ СРАВНЕНИЕ:

```
                    RNN                CNN
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Accuracy:          41.09%            88.51%
Параметры:         223K              1470K
Скорость обуч.:    Медленно          Быстро
Стабильность:      Низкая            Высокая
Переобучение:      Сильное           Слабое
Подходит для:      Последовательн.   Изображения
Лучший класс:      61%               92%
Худший класс:      32%               73%

ВЕРДИКТ:           ✗ НЕТ             ✓ ДА!
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**НА ЭКЗАМЕН:**

**Вопрос:** "Почему CNN лучше RNN для изображений?"

**Твой ответ:**
"CNN специально разработана для пространственных данных. Свертка детектирует локальные паттерны (края, текстуры), pooling дает устойчивость к сдвигам, а иерархия слоев строит признаки от простых к сложным. RNN создана для последовательностей и не видит двумерную структуру изображения. Результат: CNN = 88.51%, RNN = 41.09%."

**ГОТОВ К ЭКЗАМЕНУ! 💪🎓**
