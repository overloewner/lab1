# ЛАБОРАТОРНАЯ РАБОТА 3: CNN ДЛЯ БИОМЕТРИЧЕСКОЙ ИДЕНТИФИКАЦИИ
## Полный разбор от начала до конца

---

## 🎯 ЗАДАНИЕ (что требовалось сделать)

Из задания было:
**"Взять вторую лабу и поменять рекуррентную на сверточную (RNN на CNN)"**

То есть:
1. **Взять тот же датасет** (LFW, биометрия лиц)
2. **Заменить RNN/LSTM архитектуру на CNN**
3. **Сравнить результаты** с лабой 2
4. **Проверить все ли верно**

Все остальные требования остаются из лабы 2:
- Те же метрики (acc, rec, f-мера, TPR, FPR, TP, TN, FP, FN, MSE, MAE, AUC)
- ROC-кривые
- График переобучения
- Тесты на реальных примерах

---

## 📊 ШАГ 1: ДАТАСЕТ (ТОТ ЖЕ, ЧТО В ЛАБЕ 2)

### Что было сделано:

Использован тот же датасет **LFW (Labeled Faces in the Wild)**.

### Параметры загрузки:

```python
min_faces_per_person=70  # Те же 70 фото минимум
resize=0.5              # Уменьшение в 2 раза
color=False             # Grayscale (черно-белые)
```

### Результат:

```
Датасет: LFW (Labeled Faces in the Wild)
Количество изображений: 1,288 фотографий
Размер изображения: 62 × 47 пикселей ← ИЗМЕНИЛОСЬ! Было 50×37
Количество классов: 7 персон (те же)
Тип биометрии: Статическая (фотографии лиц)
Формат: grayscale (1 канал)
```

### ⚠️ ВАЖНОЕ ОТЛИЧИЕ от лабы 2:

```
Лаба 2 (RNN): 50 × 37 пикселей
Лаба 3 (CNN): 62 × 47 пикселей

Почему разница?
Разные значения resize в fetch_lfw_people
→ Разные размеры изображений после загрузки
```

### Те же 7 персон:

```
1. Ariel Sharon (77 фото)
2. Colin Powell (236 фото)
3. Donald Rumsfeld (121 фото)
4. George W Bush (530 фото) ← дисбаланс
5. Gerhard Schroeder (109 фото)
6. Hugo Chavez (71 фото)
7. Tony Blair (144 фото)

ИТОГО: 1,288 фотографий (как в лабе 2)
```

---

## 🔧 ШАГ 2: ПОДГОТОВКА ДАННЫХ ДЛЯ CNN

### 2.1. Нормализация (как в лабе 2)

```python
X_normalized = X / 255.0

Диапазон: [0, 1]
```

**Пример:**
```
Пиксель = 200 → 200/255 = 0.784
Пиксель = 50 → 50/255 = 0.196
```

### 2.2. Преобразование для CNN (КЛЮЧЕВОЕ ОТЛИЧИЕ!)

**В лабе 2 (RNN):**
```python
X.shape = (1288, 50, 37)  # (samples, timesteps, features)
                ↑    ↑
            строки  пиксели
         (последовательность)
```

**В лабе 3 (CNN):**
```python
X.shape = (1288, 62, 47, 1)  # (samples, height, width, channels)
                ↑   ↑   ↑
            высота ширина канал
          (двумерное изображение)
```

**Почему добавлен канал (4-й размер)?**

CNN требует формат (height, width, channels):
```
Grayscale: (62, 47, 1) ← 1 канал (оттенки серого)
RGB: (62, 47, 3) ← 3 канала (красный, зеленый, синий)
```

### Визуализация разницы:

**RNN видит:**
```
[
  [пиксель1, пиксель2, ..., пиксель37],  ← Шаг 1
  [пиксель1, пиксель2, ..., пиксель37],  ← Шаг 2
  ...
  [пиксель1, пиксель2, ..., пиксель37]   ← Шаг 50
]
↑ Последовательность векторов
```

**CNN видит:**
```
[
  [0.2, 0.3, 0.4, ...],  ← Строка 1
  [0.1, 0.5, 0.6, ...],  ← Строка 2
  [0.7, 0.2, 0.1, ...],  ← Строка 3
  ...
]
↑ Двумерная матрица (как изображение)
```

**Ключевое отличие:**
- RNN: обрабатывает строки ПОСЛЕДОВАТЕЛЬНО (сверху вниз)
- CNN: видит ВСЮ картину сразу, ищет локальные паттерны ВЕЗДЕ

---

## 🔀 ШАГ 3: РАЗДЕЛЕНИЕ НА TRAIN/TEST

### Параметры (отличаются от лабы 2!)

```python
test_size = 0.25  # 25% тестовая, 75% обучающая
stratify = y      # Сохранение пропорций классов
```

### Результат:

```
Обучающая выборка: 966 изображений (75%)
Тестовая выборка: 322 изображения (25%)
```

**Сравнение с лабой 2:**
```
Лаба 2 (RNN):
  Train: 901 (70%)
  Test: 387 (30%)

Лаба 3 (CNN):
  Train: 966 (75%)
  Test: 322 (25%)

Больше данных для обучения, меньше для теста
```

### Кодирование меток:

**Sparse Categorical (используется в CNN):**
```python
y = [0, 1, 2, 3, 4, 5, 6]  ← Просто числа

Loss: Sparse Categorical Crossentropy
```

**Отличие от лабы 2:**
```
Лаба 2: One-hot encoding
  [1, 0, 0, 0, 0, 0, 0] для класса 0

Лаба 3: Sparse (просто числа)
  0 для класса 0

Результат одинаковый, но Sparse экономит память!
```

---

## 🧠 ШАГ 4: ПОСТРОЕНИЕ АРХИТЕКТУРЫ CNN

### Полная архитектура:

```
ВХОДНОЙ СЛОЙ
↓
Input(62, 47, 1)  ← Высота × Ширина × Канал
↓

═══════════════════════════════════════════════════
БЛОК 1: Conv2D(32) + BatchNorm + Conv2D(32) + MaxPool + Dropout
═══════════════════════════════════════════════════
↓
Conv2D(32, kernel=3×3, activation='relu', padding='same')
↓ выход: (62, 47, 32)  ← 32 карты признаков
↓
BatchNormalization()  ← Нормализация активаций
↓ выход: (62, 47, 32)
↓
Conv2D(32, kernel=3×3, activation='relu', padding='same')
↓ выход: (62, 47, 32)
↓
MaxPooling2D(pool_size=2×2)  ← Уменьшение в 2 раза
↓ выход: (31, 23, 32)  ← Размер уменьшился!
↓
Dropout(0.25)  ← Отключаем 25% нейронов
↓

═══════════════════════════════════════════════════
БЛОК 2: Conv2D(64) + BatchNorm + Conv2D(64) + MaxPool + Dropout
═══════════════════════════════════════════════════
↓
Conv2D(64, kernel=3×3, activation='relu', padding='same')
↓ выход: (31, 23, 64)  ← 64 карты признаков
↓
BatchNormalization()
↓ выход: (31, 23, 64)
↓
Conv2D(64, kernel=3×3, activation='relu', padding='same')
↓ выход: (31, 23, 64)
↓
MaxPooling2D(pool_size=2×2)
↓ выход: (15, 11, 64)  ← Еще меньше
↓
Dropout(0.25)
↓

═══════════════════════════════════════════════════
БЛОК 3: Conv2D(128) + BatchNorm + Conv2D(128) + MaxPool + Dropout
═══════════════════════════════════════════════════
↓
Conv2D(128, kernel=3×3, activation='relu', padding='same')
↓ выход: (15, 11, 128)  ← 128 карт признаков
↓
BatchNormalization()
↓ выход: (15, 11, 128)
↓
Conv2D(128, kernel=3×3, activation='relu', padding='same')
↓ выход: (15, 11, 128)
↓
MaxPooling2D(pool_size=2×2)
↓ выход: (7, 5, 128)  ← Очень маленькое
↓
Dropout(0.25)
↓

═══════════════════════════════════════════════════
FLATTEN (Выравнивание в вектор)
═══════════════════════════════════════════════════
↓
Flatten()
↓ выход: (7×5×128 = 4,480)  ← Одномерный вектор!
↓

═══════════════════════════════════════════════════
ПОЛНОСВЯЗНЫЕ СЛОИ
═══════════════════════════════════════════════════
↓
Dense(256, activation='relu')
↓ выход: (256)
↓
BatchNormalization()
↓ выход: (256)
↓
Dropout(0.5)  ← Отключаем 50% нейронов
↓
Dense(128, activation='relu')
↓ выход: (128)
↓
BatchNormalization()
↓ выход: (128)
↓
Dropout(0.5)
↓

═══════════════════════════════════════════════════
ВЫХОДНОЙ СЛОЙ
═══════════════════════════════════════════════════
↓
Dense(7, activation='softmax')
↓ выход: (7)  ← Вероятности для 7 классов
```

### Параметры модели:

```
Всего параметров: 1,469,799

Сравнение с RNN:
Лаба 2 (RNN): ~500,000 параметров
Лаба 3 (CNN): 1,469,799 параметров

CNN в 3 раза больше параметров!
```

---

## 🔍 КАК РАБОТАЕТ CNN (подробно)

### Что такое свертка (Convolution):

**Свертка** - это операция скользящего окна (фильтра) по изображению.

### Фильтр (Kernel) 3×3:

```
Фильтр (веса):
┌─────────┐
│ -1  0  1│
│ -2  0  2│  ← Детектор вертикального края
│ -1  0  1│
└─────────┘
```

### Пример работы свертки:

**Исходное изображение (фрагмент глаза):**
```
Пиксели (9×9):
0.1  0.1  0.1  0.9  0.9  0.9  0.9  0.9  0.9
0.1  0.1  0.1  0.9  0.9  0.9  0.9  0.9  0.9
0.1  0.1  0.1  0.9  0.9  0.9  0.9  0.9  0.9
0.2  0.2  0.2  0.8  0.8  0.8  0.8  0.8  0.8
         ↑
    Вертикальный край (граница радужки)
```

**Применение фильтра 3×3:**

**Позиция 1 (однородная область слева):**
```
Область:
0.1  0.1  0.1
0.1  0.1  0.1
0.1  0.1  0.1

Фильтр:
-1   0   1
-2   0   2
-1   0   1

Свертка (поэлементное умножение + сумма):
= (-1×0.1 + 0×0.1 + 1×0.1) +
  (-2×0.1 + 0×0.1 + 2×0.1) +
  (-1×0.1 + 0×0.1 + 1×0.1)
= (0) + (0) + (0) = 0

→ НЕТ края (однородная область)
```

**Позиция 2 (на границе):**
```
Область:
0.1  0.1  0.9  ← темное → СВЕТЛОЕ!
0.1  0.1  0.9
0.1  0.1  0.9

Фильтр:
-1   0   1
-2   0   2
-1   0   1

Свертка:
= (-1×0.1 + 0×0.1 + 1×0.9) +
  (-2×0.1 + 0×0.1 + 2×0.9) +
  (-1×0.1 + 0×0.1 + 1×0.9)
= (0.8) + (1.6) + (0.8) = 3.2

→ СИЛЬНЫЙ вертикальный край обнаружен! ✓
```

**Позиция 3 (однородная область справа):**
```
Область:
0.9  0.9  0.9
0.9  0.9  0.9
0.9  0.9  0.9

Свертка:
= (-1×0.9 + 0×0.9 + 1×0.9) +
  (-2×0.9 + 0×0.9 + 2×0.9) +
  (-1×0.9 + 0×0.9 + 1×0.9)
= (0) + (0) + (0) = 0

→ НЕТ края
```

**Результат свертки (карта признаков):**
```
Исходное изображение (9×9):
[области темные] [КРАЙ!] [области светлые]

Карта признаков после свертки:
[0, 0, 0] [3.2, 3.1, 3.3] [0, 0, 0]
          ↑
    Обнаружен вертикальный край!
```

### Множество фильтров:

**Conv2D(32)** означает 32 разных фильтра:
```
Фильтр 1: Вертикальный край ─│
Фильтр 2: Горизонтальный край ─
Фильтр 3: Диагональный край ╱
Фильтр 4: Угол ┐
Фильтр 5: Кривая ⌒
...
Фильтр 32: Сложный паттерн

Результат: 32 карты признаков (каждая 62×47)
```

### Что обнаруживают фильтры в слоях:

**Блок 1 (Conv2D(32)):**
```
Простые признаки:
- Вертикальные края (граница носа)
- Горизонтальные края (линия бровей)
- Диагональные края (контур лица)
- Углы
- Точки
```

**Блок 2 (Conv2D(64)):**
```
Средние признаки (комбинации простых):
- Форма глаза (круг из краев)
- Контур носа (треугольник)
- Линия рта
- Форма брови
- Текстура кожи
```

**Блок 3 (Conv2D(128)):**
```
Сложные признаки:
- Полная форма лица
- Расположение глаз относительно носа
- Пропорции лица
- Уникальные черты человека
- Выражение лица
```

---

## 🏊 MaxPooling (Подвыборка)

### Что делает MaxPooling2D(2×2):

**Уменьшает размер** карты признаков, оставляя только максимальные значения.

### Пример:

**До MaxPooling (4×4):**
```
Карта признаков:
┌──────────────┐
│ 0.1  0.3  0.2  0.1 │
│ 0.5  0.9  0.7  0.4 │
│ 0.2  0.6  0.3  0.2 │
│ 0.1  0.2  0.1  0.1 │
└──────────────┘
```

**Разбиваем на окна 2×2:**
```
Окно 1:          Окно 2:
0.1  0.3         0.2  0.1
0.5  0.9         0.7  0.4
max = 0.9        max = 0.7

Окно 3:          Окно 4:
0.2  0.6         0.3  0.2
0.1  0.2         0.1  0.1
max = 0.6        max = 0.3
```

**После MaxPooling (2×2):**
```
Результат:
┌────────┐
│ 0.9  0.7 │
│ 0.6  0.3 │
└────────┘

Размер уменьшился в 2 раза по каждому измерению!
4×4 → 2×2
```

### Зачем MaxPooling:

1. **Уменьшение размерности:**
   ```
   62×47 → 31×23 → 15×11 → 7×5
   Параметров меньше → быстрее обучение
   ```

2. **Инвариантность к сдвигам:**
   ```
   Если глаз сдвинут на 1 пиксель:
   До pooling: разные карты
   После pooling: те же максимумы → одинаковый результат!
   ```

3. **Фокус на важном:**
   ```
   Max = самый сильный отклик фильтра
   → самый яркий признак в области
   ```

---

## 🔄 BatchNormalization (Нормализация батчей)

### Что делает:

Нормализует активации слоя: **среднее = 0, дисперсия = 1** для каждого батча.

### Формула:

```
x_norm = (x - μ_batch) / √(σ²_batch + ε)

где:
μ_batch = среднее значение в батче
σ²_batch = дисперсия в батче
ε = малое число (10⁻⁸) для избежания деления на 0
```

### Пример:

**Активации после Conv2D (батч из 32 изображений):**
```
Карта признаков №5 (для фильтра №5):
Изображение 1: [0.2, 0.5, 0.9, ...]
Изображение 2: [0.1, 0.3, 0.7, ...]
...
Изображение 32: [0.3, 0.6, 1.1, ...]

Для каждого пикселя карты вычисляем:
μ_batch = среднее по 32 изображениям
σ_batch = стандартное отклонение по 32 изображениям

Затем нормализуем:
x_norm = (x - μ) / σ
```

### Зачем BatchNorm:

1. **Стабилизация обучения:**
   ```
   Без BatchNorm:
   Слой 1: активации [0.1, 0.3, 0.5]
   Слой 10: активации [0.0001, 100, 50] ← НЕСТАБИЛЬНО!

   С BatchNorm:
   Все слои: активации ≈ [0, 1] ← СТАБИЛЬНО
   ```

2. **Быстрее обучение:**
   Можно использовать больший learning rate.

3. **Регуляризация:**
   Добавляет немного шума (разные батчи → разная нормализация).

---

## 🏋️ ШАГ 5: ОБУЧЕНИЕ МОДЕЛИ

### Параметры обучения:

```
Epochs: 50 (максимум)
Batch size: 32
Optimizer: Adam (lr=0.001)
Loss function: Sparse Categorical Crossentropy
Validation split: 0.2 (20% от train)
```

### Разбивка данных:

```
Всего: 1,288 изображений

Train (75%): 966 изображений
  ├─ Обучающие (80%): 773 изображения
  └─ Валидационные (20%): 193 изображения

Test (25%): 322 изображения
```

### Callbacks (те же, что в лабе 2):

```
EarlyStopping:
  monitor='val_loss'
  patience=10
  restore_best_weights=True

ReduceLROnPlateau:
  monitor='val_loss'
  factor=0.5
  patience=5
  min_lr=1e-7
```

---

## 📊 ШАГ 6: РЕЗУЛЬТАТЫ ОБУЧЕНИЯ

### ⚠️ ПРОБЛЕМА! Очень плохие результаты:

```
Train Accuracy: 0.6321 (63.21%)
Validation Accuracy: 0.1856 (18.56%)
Разница (Overfitting): 0.4466 (44.66%)

Оценка: СИЛЬНОЕ ПЕРЕОБУЧЕНИЕ ✗
```

**Что это значит:**
```
На обучающих данных: 63% правильно
На валидационных: 18% правильно

Случайное угадывание: 14.3% (1/7)
Валидация почти как случайная!

Модель ПЕРЕОБУЧИЛАСЬ!
```

### Тестовые метрики (еще хуже):

```
Test Accuracy: 0.0839 (8.39%)

8.39% < 14.3% (случайное угадывание)

Модель работает ХУЖЕ случайного! ✗✗✗
```

---

## 📈 ШАГ 7: АНАЛИЗ МЕТРИК

### 7.1. Основные метрики:

```
Accuracy: 0.0839 (8.39%) ← КАТАСТРОФА
Recall (macro): 0.1429 (14.29%)
F1-Score (macro): 0.0221 (2.21%) ← ОЧЕНЬ плохо
```

### 7.2. TPR и FPR:

```
TPR (True Positive Rate): 0.1429 (14.29%)
FPR (False Positive Rate): 0.1527 (15.27%)

TPR ≈ FPR → Модель работает случайно!
```

### 7.3. Confusion Matrix (усредненные):

```
TP (True Positives): 3.86  ← мало!
TN (True Negatives): 233.86
FP (False Positives): 42.14  ← много ложных
FN (False Negatives): 42.14  ← много пропусков
```

### 7.4. MSE и MAE:

```
MSE: 0.1282
MAE: 0.2463

Большие ошибки предсказания!
```

### 7.5. AUC:

```
Mean AUC: 0.6156

Лучше случайного (0.5), но плохо (норма >0.85)
```

---

## 🔍 ПОЧЕМУ CNN ПОКАЗАЛА ПЛОХИЕ РЕЗУЛЬТАТЫ

### Проблема 1: СИЛЬНОЕ ПЕРЕОБУЧЕНИЕ

```
Train Accuracy: 63%
Validation Accuracy: 18%
Test Accuracy: 8%

График:
Эпоха →
      0   10   20   30   40   50
Train │   ╱────────────────────  63%
Val   │  ╱╲
      │ ╱  ╲___________________  18%

Модель запомнила обучающую выборку!
```

**Причины переобучения:**

1. **Мало данных:**
   ```
   Обучающих изображений: 773
   Параметров модели: 1,469,799

   Соотношение: 1 изображение на 1,900 параметров!

   Нужно хотя бы 10,000+ изображений для такой модели
   ```

2. **Сложная архитектура:**
   ```
   3 блока Conv2D
   2 Dense слоя (256, 128)
   Всего 1.5 млн параметров

   Слишком мощная модель для малого датасета!
   ```

3. **Дисбаланс классов:**
   ```
   George W Bush: 530 фото (41%)
   Hugo Chavez: 71 фото (5.5%)

   Модель переобучилась на George W Bush
   ```

4. **Dropout недостаточен:**
   ```
   Dropout(0.25) в Conv слоях
   Dropout(0.5) в Dense слоях

   Нужно больше регуляризации!
   ```

### Проблема 2: BatchNorm с малым батчем

```
Batch size: 32

При малых батчах:
μ_batch и σ_batch нестабильны
→ BatchNorm работает плохо
```

### Проблема 3: Нет аугментации данных

**Не использовались:**
- Повороты изображений
- Сдвиги
- Изменение яркости
- Зеркальное отражение

**Результат:** Модель видит каждое изображение только в одном виде → запоминает.

---

## 📊 СРАВНЕНИЕ С ЛАБОЙ 2 (RNN)

### Сводная таблица:

```
┌─────────────────────┬─────────────┬─────────────┬────────────┐
│ Метрика             │ Лаба 2 (RNN)│ Лаба 3 (CNN)│ Победитель │
├─────────────────────┼─────────────┼─────────────┼────────────┤
│ Accuracy            │ 0.4109 (41%)│ 0.0839 (8%) │ RNN ✓      │
│ Recall (macro)      │ 0.1429      │ 0.1429      │ =          │
│ F1-Score (macro)    │ 0.0832      │ 0.0221      │ RNN ✓      │
│ TPR                 │ 0.4109      │ 0.1429      │ RNN ✓      │
│ FPR                 │ 0.0982      │ 0.1527      │ RNN ✓      │
│ MSE                 │ 0.1089      │ 0.1282      │ RNN ✓      │
│ MAE                 │ 0.2185      │ 0.2463      │ RNN ✓      │
│ Mean AUC            │ 0.5068      │ 0.6156      │ CNN ✓      │
│                     │             │             │            │
│ Train Accuracy      │ 0.4118      │ 0.6321      │ CNN        │
│ Val Accuracy        │ 0.4109      │ 0.1856      │ RNN ✓      │
│ Overfitting         │ 0.0009 (0%) │ 0.4466 (45%)│ RNN ✓✓✓    │
│                     │             │             │            │
│ Параметров          │ ~500K       │ 1,470K      │ RNN (меньше)│
│ Скорость обучения   │ Медленно    │ Быстро      │ CNN ✓      │
└─────────────────────┴─────────────┴─────────────┴────────────┘

Итог: RNN ЛУЧШЕ по большинству метрик!
```

### Почему RNN оказалась лучше:

**Не потому что RNN хороша для изображений (она плоха!)**

**А потому что CNN в этой лабе:**
1. Сильно переобучилась (44% overfitting vs 0% у RNN)
2. Плохо настроена для малого датасета
3. Не использует аугментацию

**Правильно настроенная CNN должна быть намного лучше!**

---

## ✅ КАК ПРАВИЛЬНО СДЕЛАТЬ CNN

### Рекомендации для исправления:

#### 1. Уменьшить количество параметров:

```python
# Вместо:
Dense(256) → Dense(128) → Dense(7)

# Сделать:
Dense(64) → Dense(7)

Параметров станет меньше → меньше переобучение
```

#### 2. Больше регуляризации:

```python
# Увеличить Dropout:
Dropout(0.5) в Conv слоях
Dropout(0.7) в Dense слоях

# Добавить L2 регуляризацию:
Conv2D(32, kernel_regularizer=l2(0.01))
```

#### 3. Аугментация данных:

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

augment = ImageDataGenerator(
    rotation_range=20,      # Поворот ±20°
    width_shift_range=0.2,  # Сдвиг по ширине
    height_shift_range=0.2, # Сдвиг по высоте
    horizontal_flip=True,   # Зеркальное отражение
    zoom_range=0.2          # Зум
)

# Увеличивает датасет в 10-20 раз!
```

#### 4. Балансировка классов:

```python
# Взвешивание классов:
class_weight = {
    0: 1.0,  # Ariel Sharon
    1: 0.5,  # Colin Powell
    2: 0.8,  # Donald Rumsfeld
    3: 0.2,  # George W Bush (меньший вес!)
    4: 0.9,  # Gerhard Schroeder
    5: 1.2,  # Hugo Chavez (больший вес!)
    6: 0.7   # Tony Blair
}

model.fit(..., class_weight=class_weight)
```

#### 5. Упрощенная архитектура для малого датасета:

```
Input(62, 47, 1)
↓
Conv2D(32) → MaxPool → Dropout(0.3)
↓
Conv2D(64) → MaxPool → Dropout(0.4)
↓
Flatten
↓
Dense(64) → Dropout(0.5)
↓
Dense(7, softmax)

Параметров: ~200,000 (вместо 1,470,000)
```

#### 6. Transfer Learning:

```python
# Использовать предобученную модель:
from tensorflow.keras.applications import VGG16

base_model = VGG16(weights='imagenet', include_top=False)
base_model.trainable = False  # Заморозить веса

# Добавить свои слои сверху
```

---

## 🎯 ЧТО CNN ДЕЛАЕТ ЛУЧШЕ RNN (теоретически)

### Преимущества CNN для изображений:

#### 1. Локальные паттерны:

**CNN:**
```
Фильтр 3×3 видит:
░░░
░█░  ← Угол глаза
░░░

Обнаруживает локальные признаки в любом месте изображения!
```

**RNN:**
```
Обрабатывает строку:
[пиксель1, пиксель2, ..., пиксель37]

Не видит связи между соседними строками!
```

#### 2. Иерархия признаков:

**CNN:**
```
Слой 1: Края и углы
          ↓
Слой 2: Глаза, нос, рот (комбинация краев)
          ↓
Слой 3: Полное лицо (комбинация частей)

Иерархия от простого к сложному!
```

**RNN:**
```
Шаг 1: Строка 1
Шаг 2: Строка 2
...
Шаг 50: Строка 50

Только последовательная обработка
```

#### 3. Инвариантность к сдвигам:

**CNN + MaxPooling:**
```
Глаз в позиции (20, 15):
MaxPool → max значение

Глаз сдвинут в (21, 16):
MaxPool → тот же max!

Результат не меняется от малого сдвига
```

**RNN:**
```
Глаз в строке 20 → состояние h_20
Глаз в строке 21 → другое состояние h_21

Чувствительна к позиции!
```

#### 4. Weight sharing (разделение весов):

**CNN:**
```
Один фильтр 3×3 = 9 весов
Применяется ко ВСЕМУ изображению (62×47 позиций)

Параметров мало, но покрытие полное!
```

**RNN:**
```
Отдельные веса для каждой позиции
Много параметров!
```

---

## 🧪 ШАГ 8: ТЕСТЫ НА РЕАЛЬНЫХ ПРИМЕРАХ

### Типичные результаты:

**Пример 1:**
```
Истинный класс: George W Bush
Предсказанный: Ariel Sharon
Уверенность: 25%
Результат: ✗ ОШИБКА
```

**Пример 2:**
```
Истинный класс: Colin Powell
Предсказанный: George W Bush
Уверенность: 18%
Результат: ✗ ОШИБКА
```

**Пример 3:**
```
Истинный класс: Hugo Chavez
Предсказанный: Donald Rumsfeld
Уверенность: 22%
Результат: ✗ ОШИБКА
```

**Анализ:**
- Очень низкая уверенность (18-25%) → модель сомневается
- Частые ошибки → accuracy 8%
- Случайные предсказания → переобучение

---

## 🎓 ВЫВОДЫ

### 1. Результаты лабы 3:

**❌ CNN показала ХУДШИЕ результаты, чем RNN:**
```
Accuracy: 8.4% vs 41% (RNN лучше в 5 раз!)
Overfitting: 44.7% vs 0.09% (RNN почти без переобучения)
AUC: 0.62 vs 0.51 (CNN немного лучше)
```

### 2. Почему так плохо:

**НЕ потому что CNN плоха для изображений!**

**А потому что:**
1. Сильное переобучение (773 изображения, 1.5M параметров)
2. Нет аугментации данных
3. Дисбаланс классов не учтен
4. Слишком сложная архитектура для малого датасета
5. BatchNorm с малым батчем

### 3. Теоретически CNN должна быть лучше:

**CNN создана для изображений:**
- ✓ Локальные паттерны (края, текстуры)
- ✓ Иерархия признаков (от простых к сложным)
- ✓ Инвариантность к сдвигам (MaxPooling)
- ✓ Эффективность (weight sharing)

**RNN создана для последовательностей:**
- ✗ Обрабатывает по строкам (теряет 2D структуру)
- ✗ Не видит локальные паттерны
- ✗ Чувствительна к позиции

### 4. Практические результаты в реальности:

**С большими датасетами (ImageNet, 1M+ изображений):**
```
CNN Accuracy: 95-98%
RNN Accuracy: 30-40%

CNN намного лучше!
```

**Наш случай (малый датасет 1,288 изображений):**
```
CNN: 8% (переобучилась)
RNN: 41% (не переобучилась, но и не научилась)

RNN лучше из-за МЕНЬШЕГО переобучения, а не потому что лучше для изображений!
```

### 5. Итоговая таблица:

```
┌──────────────────────┬─────┬─────┬──────────────┐
│ Критерий             │ RNN │ CNN │ Должно быть  │
├──────────────────────┼─────┼─────┼──────────────┤
│ Accuracy (факт)      │ 41% │ 8%  │ CNN > RNN    │
│ Accuracy (теория)    │ 30% │ 95% │ CNN ✓✓✓      │
│ Overfitting (факт)   │ 0%  │ 45% │ CNN хуже ✗   │
│ Подходит для фото    │ ✗   │ ✓   │ CNN ✓        │
│ Параметров           │ 500K│1470K│ Больше → хуже│
│ Нужно данных         │ 1K+ │ 10K+│ Мало данных! │
└──────────────────────┴─────┴─────┴──────────────┘
```

### 6. Ответ на задание:

**Задание:** "Взять лабу 2 и заменить RNN на CNN"

**Выполнено:**
- ✓ Тот же датасет LFW
- ✓ RNN заменена на CNN
- ✓ Все метрики вычислены
- ✓ Сравнение проведено

**Результат:**
- ✗ CNN хуже RNN (8% vs 41%)
- Причина: переобучение на малом датасете
- Вывод: нужна оптимизация (аугментация, меньше параметров, регуляризация)

### 7. Рекомендации:

**Для улучшения CNN:**
1. Аугментация данных (×10-20 увеличение)
2. Упрощение архитектуры (меньше параметров)
3. Сильная регуляризация (больше Dropout)
4. Балансировка классов
5. Больше данных (найти дополнительные фото)

**Ожидаемый результат после оптимизации:**
```
CNN Accuracy: 70-85% (вместо 8%)
Overfitting: < 10% (вместо 45%)

Это сделает CNN намного лучше RNN!
```

---

**КОНЕЦ РАЗБОРА ЛАБОРАТОРНОЙ РАБОТЫ 3**

**ОБЩИЙ ВЫВОД ПО ВСЕМ ТРЕМ ЛАБАМ:**

```
Лаба 1 (Кластеризация):
  ✓ K-means++ лучший для классификации (AUC 0.72)
  ✓ Агломеративная (manhattan) лучшая для кластеризации (Silhouette 0.81)

Лаба 2 (RNN):
  ~ Accuracy 41% (лучше случайного, но плохо)
  ✓ Нет переобучения (0.09%)
  ✗ RNN не подходит для изображений

Лаба 3 (CNN):
  ✗ Accuracy 8% (хуже RNN!)
  ✗ Сильное переобучение (45%)
  ✓ Теоретически правильный выбор для изображений
  → Нужна оптимизация!

Для идеального результата:
  CNN с аугментацией + больше данных → Accuracy 85-95%
```
