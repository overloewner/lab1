# –¢–µ–æ—Ä–∏—è —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (CNN)

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. –í–≤–µ–¥–µ–Ω–∏–µ –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ
2. –û—Ç –æ–±—ã—á–Ω—ã—Ö —Å–µ—Ç–µ–π –∫ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–º
3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN
4. –°–ª–æ–∏ CNN
5. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
6. –û–±—É—á–µ–Ω–∏–µ CNN
7. Transfer Learning
8. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ CNN
9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

---

## 1. –í–≤–µ–¥–µ–Ω–∏–µ –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ

### 1.1 –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ?

**Computer Vision (CV)** ‚Äî –æ–±–ª–∞—Å—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∑–∞–Ω–∏–º–∞—é—â–∞—è—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º, –∞–Ω–∞–ª–∏–∑–æ–º –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ.

### 1.2 –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ CV

#### –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Image Classification)
```
–í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
–í—ã—Ö–æ–¥: –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞
–ü—Ä–∏–º–µ—Ä: "—ç—Ç–æ –∫–æ—à–∫–∞"
```

#### –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ (Object Detection)
```
–í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
–í—ã—Ö–æ–¥: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ —Ä–∞–º–∫–∏ + –º–µ—Ç–∫–∏
–ü—Ä–∏–º–µ—Ä: "–∫–æ—à–∫–∞ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö (x1, y1, x2, y2)"
```

#### –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (Semantic Segmentation)
```
–í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
–í—ã—Ö–æ–¥: –º–∞—Å–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è
–ü—Ä–∏–º–µ—Ä: –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ "–∫–æ—à–∫–∞", "—Ñ–æ–Ω", "—Ç—Ä–∞–≤–∞"
```

#### –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü (Face Recognition)
```
–í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞
–í—ã—Ö–æ–¥: ID —á–µ–ª–æ–≤–µ–∫–∞
```

#### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Image Generation)
```
–í—Ö–æ–¥: —Ç–µ–∫—Å—Ç/—à—É–º
–í—ã—Ö–æ–¥: —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
–ü—Ä–∏–º–µ—Ä: GANs, Diffusion models
```

### 1.3 –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**–¶–∏—Ñ—Ä–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ** = –º–∞—Ç—Ä–∏—Ü–∞ –ø–∏–∫—Å–µ–ª–µ–π

#### Grayscale (–æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ)
```
–†–∞–∑–º–µ—Ä: Height √ó Width
–ó–Ω–∞—á–µ–Ω–∏—è: [0, 255]
0 = —á–µ—Ä–Ω—ã–π, 255 = –±–µ–ª—ã–π
```

–ü—Ä–∏–º–µ—Ä 5√ó5:
```
[  0  50 100 150 200]
[ 25  75 125 175 225]
[ 50 100 150 200 250]
[ 75 125 175 225 255]
[100 150 200 250 255]
```

#### RGB (—Ü–≤–µ—Ç–Ω–æ–µ)
```
–†–∞–∑–º–µ—Ä: Height √ó Width √ó 3
–ö–∞–Ω–∞–ª—ã: Red, Green, Blue
–ö–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª: [0, 255]
```

–ü—Ä–∏–º–µ—Ä –ø–∏–∫—Å–µ–ª—è:
```
Red   = 255
Green = 100
Blue  = 50
‚Üí –û—Ä–∞–Ω–∂–µ–≤—ã–π —Ü–≤–µ—Ç
```

#### –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
–û–±—ã—á–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç –∫ [0, 1] –∏–ª–∏ [-1, 1]:
```python
# [0, 1]
image_normalized = image / 255.0

# [-1, 1]
image_normalized = (image - 127.5) / 127.5
```

---

## 2. –û—Ç –æ–±—ã—á–Ω—ã—Ö —Å–µ—Ç–µ–π –∫ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–º

### 2.1 –ü—Ä–æ–±–ª–µ–º—ã –æ–±—ã—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

#### –ü—Ä–æ–±–ª–µ–º–∞ 1: –û–≥—Ä–æ–º–Ω–æ–µ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**–ü—Ä–∏–º–µ—Ä:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224√ó224√ó3 (RGB)
= 224 √ó 224 √ó 3 = 150,528 –ø–∏–∫—Å–µ–ª–µ–π

–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 1000 –Ω–µ–π—Ä–æ–Ω–∞–º–∏:
150,528 √ó 1000 = 150,528,000 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ 1 —Å–ª–æ–π!)
```

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- –û–≥—Ä–æ–º–Ω–∞—è –ø–∞–º—è—Ç—å
- –õ–µ–≥–∫–æ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è

#### –ü—Ä–æ–±–ª–µ–º–∞ 2: –ü–æ—Ç–µ—Ä—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è —Å–µ—Ç—å "—Ä–∞—Å–ø–ª—é—â–∏–≤–∞–µ—Ç" –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:
```
[H √ó W √ó C] ‚Üí [H*W*C √ó 1]
```

–¢–µ—Ä—è–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ:
- –°–æ—Å–µ–¥–Ω–∏—Ö –ø–∏–∫—Å–µ–ª—è—Ö
- –õ–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
- –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö

#### –ü—Ä–æ–±–ª–µ–º–∞ 3: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ —Å–¥–≤–∏–≥–∞–º

–ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç —Å–¥–≤–∏–Ω—É—Ç –Ω–∞ –ø–∞—Ä—É –ø–∏–∫—Å–µ–ª–µ–π, —Å–µ—Ç—å –º–æ–∂–µ—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –µ–≥–æ.

### 2.2 –ò–¥–µ–∏ CNN

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:**

1. **–õ–æ–∫–∞–ª—å–Ω–∞—è —Å–≤—è–∑–Ω–æ—Å—Ç—å (Local Connectivity)**
   - –ù–µ–π—Ä–æ–Ω —Å–º–æ—Ç—Ä–∏—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–µ–±–æ–ª—å—à—É—é –æ–±–ª–∞—Å—Ç—å (receptive field)
   - –£–º–µ–Ω—å—à–∞–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

2. **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ (Weight Sharing)**
   - –û–¥–Ω–∏ –∏ —Ç–µ –∂–µ –≤–µ—Å–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∫–æ –≤—Å–µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
   - –î–µ—Ç–µ–∫—Ç–æ—Ä –∫—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ –æ–¥–∏–Ω–∞–∫–æ–≤–æ

3. **–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è (Spatial Hierarchy)**
   - –ù–∏–∑–∫–∏–µ —Å–ª–æ–∏: –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫—Ä–∞—è, —Ç–µ–∫—Å—Ç—É—Ä—ã)
   - –í—ã—Å–æ–∫–∏–µ —Å–ª–æ–∏: —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—á–∞—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–æ–≤, —Ü–µ–ª—ã–µ –æ–±—ä–µ–∫—Ç—ã)

**–í–∏–∑—É–∞–ª—å–Ω–æ:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí [–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å]  ‚Üí [–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å] ‚Üí [–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å]
   üê±      ‚Üí –≥—Ä–∞–Ω–∏, —É–≥–ª—ã       ‚Üí —É—à–∏, –≥–ª–∞–∑–∞, –Ω–æ—Å   ‚Üí "—ç—Ç–æ –∫–æ—à–∫–∞"
```

---

## 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN

### 3.1 –¢–∏–ø–∏—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
Input Image
    ‚Üì
[Conv + ReLU] ‚Üí [Pooling]  ‚îÄ‚îê
[Conv + ReLU] ‚Üí [Pooling]   ‚îÇ Feature Extraction
[Conv + ReLU] ‚Üí [Pooling]  ‚îÄ‚îò
    ‚Üì
[Flatten]
    ‚Üì
[Dense + ReLU]  ‚îÄ‚îê
[Dense + ReLU]   ‚îÇ Classification
[Dense (output)] ‚îÄ‚îò
```

### 3.2 –ü—Ä–∏–º–µ—Ä: LeNet-5 (1998)

```
Input: 32√ó32 grayscale
    ‚Üì
Conv1: 6 —Ñ–∏–ª—å—Ç—Ä–æ–≤ 5√ó5 ‚Üí 28√ó28√ó6
    ‚Üì
AvgPool: 2√ó2 ‚Üí 14√ó14√ó6
    ‚Üì
Conv2: 16 —Ñ–∏–ª—å—Ç—Ä–æ–≤ 5√ó5 ‚Üí 10√ó10√ó16
    ‚Üì
AvgPool: 2√ó2 ‚Üí 5√ó5√ó16
    ‚Üì
Flatten ‚Üí 400
    ‚Üì
FC1: 120 –Ω–µ–π—Ä–æ–Ω–æ–≤
    ‚Üì
FC2: 84 –Ω–µ–π—Ä–æ–Ω–∞
    ‚Üì
Output: 10 –∫–ª–∞—Å—Å–æ–≤ (—Ü–∏—Ñ—Ä—ã 0-9)
```

### 3.3 –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ

**–§–æ—Ä–º—É–ª–∞ –¥–ª—è —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è:**
```
Output_size = (Input_size - Kernel_size + 2*Padding) / Stride + 1
```

**–ü—Ä–∏–º–µ—Ä:**
```
Input: 224√ó224
Kernel: 3√ó3
Padding: 1
Stride: 1

Output = (224 - 3 + 2*1) / 1 + 1 = 224√ó224
```

**–ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:**
```
Conv —Å–ª–æ–π:
Params = (Kernel_H √ó Kernel_W √ó Input_Channels + 1) √ó Num_Filters

–ü—Ä–∏–º–µ—Ä:
–í—Ö–æ–¥: 224√ó224√ó3
–§–∏–ª—å—Ç—Ä: 3√ó3, 64 —Ñ–∏–ª—å—Ç—Ä–∞
Params = (3 √ó 3 √ó 3 + 1) √ó 64 = 1,792
```

---

## 4. –°–ª–æ–∏ CNN

### 4.1 Convolutional Layer (–°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π)

#### –ß—Ç–æ —Ç–∞–∫–æ–µ —Å–≤–µ—Ä—Ç–∫–∞?

**–°–≤–µ—Ä—Ç–∫–∞** = —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ + –ø–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ + —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ

**–í–∏–∑—É–∞–ª—å–Ω–æ:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:        –§–∏–ª—å—Ç—Ä (Kernel):
[1 2 3 4]           [1 0]
[5 6 7 8]           [0 -1]
[9 0 1 2]

–®–∞–≥ 1: –ø–æ–∑–∏—Ü–∏—è (0,0)
[1 2] ‚äô [1  0] = 1*1 + 2*0 + 5*0 + 6*(-1) = -5
[5 6]   [0 -1]

–®–∞–≥ 2: –ø–æ–∑–∏—Ü–∏—è (0,1)
[2 3] ‚äô [1  0] = 2*1 + 3*0 + 6*0 + 7*(-1) = -5
[6 7]   [0 -1]

...

–†–µ–∑—É–ª—å—Ç–∞—Ç (Feature Map):
[-5 -5 -5]
[-3 -3 -3]
```

#### –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

**1. Kernel Size (—Ä–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞)**
- 3√ó3, 5√ó5, 7√ó7 ‚Äî —Ç–∏–ø–∏—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
- –ú–µ–Ω—å—à–µ —è–¥—Ä–æ ‚Üí –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
- –ë–æ–ª—å—à–µ —è–¥—Ä–æ ‚Üí –±–æ–ª—å—à–µ receptive field

**2. Number of Filters (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤)**
- –ö–∞–∂–¥—ã–π —Ñ–∏–ª—å—Ç—Ä —É—á–∏—Ç—Å—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫
- 32, 64, 128, 256, 512 ‚Äî —Ç–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- –ë–æ–ª—å—à–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ ‚Üí –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–æ –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**3. Stride (—à–∞–≥)**
- –®–∞–≥ —Å–¥–≤–∏–≥–∞ —Ñ–∏–ª—å—Ç—Ä–∞
- Stride=1: –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å
- Stride=2: –∫–∞–∂–¥—ã–π –≤—Ç–æ—Ä–æ–π –ø–∏–∫—Å–µ–ª—å (—É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä)

**4. Padding (–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ)**
- `valid`: –±–µ–∑ padding (—Ä–∞–∑–º–µ—Ä —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è)
- `same`: padding —Ç–∞–∫, —á—Ç–æ–±—ã —Ä–∞–∑–º–µ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è

#### –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤

**–î–µ—Ç–µ–∫—Ç–æ—Ä –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü:**
```
[-1  0  1]
[-2  0  2]
[-1  0  1]
```
(Sobel filter)

**–î–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü:**
```
[-1 -2 -1]
[ 0  0  0]
[ 1  2  1]
```

**–†–∞–∑–º—ã—Ç–∏–µ (Blur):**
```
1/9 √ó [1 1 1]
      [1 1 1]
      [1 1 1]
```

**–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏:**
```
[ 0 -1  0]
[-1  5 -1]
[ 0 -1  0]
```

### 4.2 Activation Layer (–§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)

#### ReLU (Rectified Linear Unit)
```
f(x) = max(0, x)
```

**–ì—Ä–∞—Ñ–∏–∫:**
```
    ‚îÇ    ‚ï±
    ‚îÇ   ‚ï±
    ‚îÇ  ‚ï±
‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ
```

**–°–≤–æ–π—Å—Ç–≤–∞:**
‚úì –ü—Ä–æ—Å—Ç–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è  
‚úì –ù–µ –Ω–∞—Å—ã—â–∞–µ—Ç—Å—è –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π  
‚úì –†–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è (–º–Ω–æ–≥–æ –Ω—É–ª–µ–π)  

‚úó "–ú–µ—Ä—Ç–≤—ã–µ" –Ω–µ–π—Ä–æ–Ω—ã (–µ—Å–ª–∏ –≤—Ö–æ–¥ –≤—Å–µ–≥–¥–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π)  

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏:**

**Leaky ReLU:**
```
f(x) = max(0.01x, x)
```
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É "–º–µ—Ä—Ç–≤—ã—Ö" –Ω–µ–π—Ä–æ–Ω–æ–≤

**ELU (Exponential Linear Unit):**
```
f(x) = x,              –µ—Å–ª–∏ x > 0
     = Œ±(e^x - 1),     –µ—Å–ª–∏ x ‚â§ 0
```

#### –î—Ä—É–≥–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏

**Sigmoid:**
```
œÉ(x) = 1 / (1 + e^(-x))
```
–†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (–ø—Ä–æ–±–ª–µ–º–∞ –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤)

**Tanh:**
```
tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))
```

**Softmax (–ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π):**
```
œÉ(x_i) = e^(x_i) / Œ£_j e^(x_j)
```
–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (—Å—É–º–º–∞ = 1)

### 4.3 Pooling Layer (–°–ª–æ–π –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏)

#### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω?

1. **–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** ‚Äî —É—Å–∫–æ—Ä—è–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
2. **–£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** ‚Äî –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
3. **–ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ —Å–¥–≤–∏–≥–∞–º** ‚Äî –Ω–µ–±–æ–ª—å—à–∏–µ —Å–¥–≤–∏–≥–∏ –Ω–µ –≤–ª–∏—è—é—Ç

#### Max Pooling

**–ò–¥–µ—è:** –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º—É–º –∏–∑ –æ–∫–Ω–∞

```
Input:              2√ó2 Max Pool:
[1  3  2  4]        [3  4]
[5  6  7  8]  ‚Üí     [9  8]
[9  2  1  3]
[0  5  4  2]

–û–∫–Ω–æ 1: max(1,3,5,6) = 6 ‚Üí –Ω–µ—Ç, 3
–û–∫–Ω–æ 2: max(2,4,7,8) = 8 ‚Üí –¥–∞, 4
...
```

**–¢–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- –†–∞–∑–º–µ—Ä: 2√ó2 –∏–ª–∏ 3√ó3
- Stride: –æ–±—ã—á–Ω–æ —Ä–∞–≤–µ–Ω —Ä–∞–∑–º–µ—Ä—É (non-overlapping)

#### Average Pooling

**–ò–¥–µ—è:** —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –æ–∫–Ω–µ

```
[1  3  2  4]        [3.75  5.25]
[5  6  7  8]  ‚Üí     [4.0   2.5]
[9  2  1  3]
[0  5  4  2]
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- Max Pooling: —á–∞—â–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- Average Pooling: –∏–Ω–æ–≥–¥–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ—è—Ö (Global Average Pooling)

#### Global Pooling

**Global Average/Max Pooling:**
```
Input: H √ó W √ó C
Output: 1 √ó 1 √ó C

–ü—Ä–∏–º–µ—Ä: 7√ó7√ó512 ‚Üí 1√ó1√ó512
```

–ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤–º–µ—Å—Ç–æ Flatten –ø–µ—Ä–µ–¥ FC —Å–ª–æ—è–º–∏.

### 4.4 Batch Normalization

**–ü—Ä–æ–±–ª–µ–º–∞:** —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –º–µ–Ω—è—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (Internal Covariate Shift)

**–†–µ—à–µ–Ω–∏–µ:** –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –∫–∞–∂–¥–æ–º mini-batch

**–§–æ—Ä–º—É–ª–∞:**
```
xÃÇ = (x - Œº_batch) / ‚àö(œÉ¬≤_batch + Œµ)
y = Œ≥xÃÇ + Œ≤
```

–≥–¥–µ:
- Œº_batch, œÉ¬≤_batch ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—è –≤ –±–∞—Ç—á–µ
- Œ≥, Œ≤ ‚Äî –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–º–∞—Å—à—Ç–∞–± –∏ —Å–¥–≤–∏–≥)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
‚úì –£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ  
‚úì –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ learning rates  
‚úì –£–º–µ–Ω—å—à–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏  
‚úì –†–µ–≥—É–ª—è—Ä–∏–∑–∏—Ä—É–µ—Ç (—É–º–µ–Ω—å—à–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)  

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
```
Conv ‚Üí BatchNorm ‚Üí ReLU
```

### 4.5 Dropout

**–ò–¥–µ—è:** —Å–ª—É—á–∞–π–Ω–æ "–≤—ã–∫–ª—é—á–∞—Ç—å" –Ω–µ–π—Ä–æ–Ω—ã –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

```
–û–±—É—á–µ–Ω–∏–µ:
[0.5, 0.3, 0.8, 0.2] ‚Üí dropout(p=0.5) ‚Üí [0, 0.6, 1.6, 0]
                       (—Å–ª—É—á–∞–π–Ω–æ –ø–æ–ª–æ–≤–∏–Ω–∞ ‚Üí 0, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è)

–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:
[0.5, 0.3, 0.8, 0.2] ‚Üí (–≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–Ω—ã, –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ù–µ–π—Ä–æ–Ω—ã —É—á–∞—Ç—Å—è –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞
- –ê–Ω—Å–∞–º–±–ª—å –ø–æ–¥—Å–µ—Ç–µ–π
- –£–º–µ–Ω—å—à–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

**–¢–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:** p = 0.2-0.5

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
```
Dense ‚Üí Dropout(0.5) ‚Üí Dense
```

### 4.6 Fully Connected (Dense) Layer

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π** –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π:
```
y = W¬∑x + b
```

**–í CNN:**
- –û–±—ã—á–Ω–æ –≤ –∫–æ–Ω—Ü–µ —Å–µ—Ç–∏
- –ü–æ—Å–ª–µ Flatten –∏–ª–∏ Global Pooling
- –î–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

**–ü—Ä–∏–º–µ—Ä:**
```
Conv Layers ‚Üí Flatten ‚Üí Dense(512) ‚Üí Dense(num_classes)
```

---

## 5. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã CNN

### 5.1 AlexNet (2012)

**–ü—Ä–æ—Ä—ã–≤:** –ø–æ–±–µ–¥–∞ –≤ ImageNet 2012 —Å –æ–≥—Ä–æ–º–Ω—ã–º –æ—Ç—Ä—ã–≤–æ–º

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```
Input: 227√ó227√ó3
    ‚Üì
Conv1: 96 filters, 11√ó11, stride=4 ‚Üí 55√ó55√ó96
MaxPool: 3√ó3, stride=2 ‚Üí 27√ó27√ó96
    ‚Üì
Conv2: 256 filters, 5√ó5 ‚Üí 27√ó27√ó256
MaxPool: 3√ó3, stride=2 ‚Üí 13√ó13√ó256
    ‚Üì
Conv3: 384 filters, 3√ó3 ‚Üí 13√ó13√ó384
Conv4: 384 filters, 3√ó3 ‚Üí 13√ó13√ó384
Conv5: 256 filters, 3√ó3 ‚Üí 13√ó13√ó256
MaxPool: 3√ó3, stride=2 ‚Üí 6√ó6√ó256
    ‚Üì
Flatten ‚Üí 9216
FC1: 4096, Dropout(0.5)
FC2: 4096, Dropout(0.5)
FC3: 1000 (classes)
```

**–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏:**
- ReLU –∞–∫—Ç–∏–≤–∞—Ü–∏—è (–≤–º–µ—Å—Ç–æ tanh/sigmoid)
- Dropout
- Data Augmentation
- GPU –æ–±—É—á–µ–Ω–∏–µ

### 5.2 VGGNet (2014)

**–ò–¥–µ—è:** –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏ —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ (3√ó3)

**VGG-16:**
```
Input: 224√ó224√ó3

Block 1:
  Conv 3√ó3, 64 ‚Üí ReLU
  Conv 3√ó3, 64 ‚Üí ReLU
  MaxPool 2√ó2

Block 2:
  Conv 3√ó3, 128 ‚Üí ReLU
  Conv 3√ó3, 128 ‚Üí ReLU
  MaxPool 2√ó2

Block 3:
  Conv 3√ó3, 256 ‚Üí ReLU
  Conv 3√ó3, 256 ‚Üí ReLU
  Conv 3√ó3, 256 ‚Üí ReLU
  MaxPool 2√ó2

Block 4:
  Conv 3√ó3, 512 ‚Üí ReLU
  Conv 3√ó3, 512 ‚Üí ReLU
  Conv 3√ó3, 512 ‚Üí ReLU
  MaxPool 2√ó2

Block 5:
  Conv 3√ó3, 512 ‚Üí ReLU
  Conv 3√ó3, 512 ‚Üí ReLU
  Conv 3√ó3, 512 ‚Üí ReLU
  MaxPool 2√ó2

FC: 4096 ‚Üí 4096 ‚Üí 1000
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –¢–æ–ª—å–∫–æ 3√ó3 —Ñ–∏–ª—å—Ç—Ä—ã
- –£–¥–≤–æ–µ–Ω–∏–µ —á–∏—Å–ª–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ—Å–ª–µ pooling
- –ü—Ä–æ—Å—Ç–∞—è –∏ –ø–æ–Ω—è—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫:** –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (~138M)

### 5.3 GoogLeNet / Inception (2014)

**–ò–¥–µ—è:** Inception –º–æ–¥—É–ª–∏ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏

**Inception Module:**
```
                 Input
                   ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ          ‚îÇ          ‚îÇ          ‚îÇ
    1√ó1 Conv   1√ó1 Conv   1√ó1 Conv   MaxPool
        ‚îÇ          ‚îÇ          ‚îÇ          ‚îÇ
        ‚îÇ      3√ó3 Conv   5√ó5 Conv   1√ó1 Conv
        ‚îÇ          ‚îÇ          ‚îÇ          ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
            Concatenate (–ø–æ –∫–∞–Ω–∞–ª–∞–º)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- 1√ó1 Conv –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (bottleneck)
- –ú–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —á–µ–º VGG

### 5.4 ResNet (2015)

**–ü—Ä–æ–±–ª–µ–º–∞:** –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏ —Ç—Ä—É–¥–Ω–æ –æ–±—É—á–∞—Ç—å (degradation problem)

**–†–µ—à–µ–Ω–∏–µ:** Residual connections (skip connections)

**Residual Block:**
```
        x
        ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                 ‚îÇ
    Conv 3√ó3          (identity)
        ‚îÇ                 ‚îÇ
      ReLU                ‚îÇ
        ‚îÇ                 ‚îÇ
    Conv 3√ó3              ‚îÇ
        ‚îÇ                 ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ(+)‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
            ReLU
```

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:**
```
F(x) = H(x) - x
H(x) = F(x) + x
```

–≥–¥–µ:
- x ‚Äî –≤—Ö–æ–¥
- F(x) ‚Äî –æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (residual)
- H(x) ‚Äî –≤—ã—Ö–æ–¥ –±–ª–æ–∫–∞

**–ò–¥–µ—è:** –ª–µ–≥—á–µ –æ–±—É—á–∏—Ç—å F(x)=0, —á–µ–º H(x)=x

**–í–∞—Ä–∏–∞–Ω—Ç—ã:**
- ResNet-18, ResNet-34: –±–∞–∑–æ–≤—ã–µ –±–ª–æ–∫–∏
- ResNet-50, ResNet-101, ResNet-152: bottleneck –±–ª–æ–∫–∏

**ResNet-50:**
```
Input: 224√ó224√ó3
    ‚Üì
Conv 7√ó7, 64, stride=2
MaxPool 3√ó3, stride=2
    ‚Üì
3√ó [Residual Block (64, 64, 256)]
4√ó [Residual Block (128, 128, 512)]
6√ó [Residual Block (256, 256, 1024)]
3√ó [Residual Block (512, 512, 2048)]
    ‚Üì
Global Avg Pool
FC: 1000
```

**Bottleneck Block:**
```
1√ó1 Conv (—É–º–µ–Ω—å—à–µ–Ω–∏–µ) ‚Üí 3√ó3 Conv ‚Üí 1√ó1 Conv (—É–≤–µ–ª–∏—á–µ–Ω–∏–µ) + skip
```

### 5.5 MobileNet (2017)

**–ò–¥–µ—è:** —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤

**Depthwise Separable Convolution:**
```
–û–±—ã—á–Ω–∞—è Conv: H√óW√óC_in ‚Üí H√óW√óC_out
–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: K√óK√óC_in√óC_out

Depthwise Separable:
1. Depthwise: K√óK conv –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: K√óK√óC_in
2. Pointwise: 1√ó1 conv –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 1√ó1√óC_in√óC_out

–≠–∫–æ–Ω–æ–º–∏—è: ~8-9 —Ä–∞–∑ –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- –ú–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- –í—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ —Å–∏—Å—Ç–µ–º—ã
- Real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

### 5.6 EfficientNet (2019)

**–ò–¥–µ—è:** —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (depth, width, resolution)

**Compound Scaling:**
```
depth:      —á–∏—Å–ª–æ —Å–ª–æ–µ–≤
width:      —á–∏—Å–ª–æ –∫–∞–Ω–∞–ª–æ–≤/—Ñ–∏–ª—å—Ç—Ä–æ–≤
resolution: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞

–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ NAS (Neural Architecture Search)
```

**–í–∞—Ä–∏–∞–Ω—Ç—ã:** EfficientNet-B0 –¥–æ B7

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –º–µ–Ω—å—à–µ–º —á–∏—Å–ª–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- State-of-the-art –Ω–∞ ImageNet

### 5.7 Vision Transformer (ViT) (2020)

**–ò–¥–µ—è:** –ø—Ä–∏–º–µ–Ω–∏—Ç—å Transformer (–∏–∑ NLP) –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```
Image ‚Üí –†–∞–∑–±–∏—Ç—å –Ω–∞ –ø–∞—Ç—á–∏ ‚Üí –õ–∏–Ω–µ–π–Ω–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ ‚Üí Transformer Encoder ‚Üí MLP Head
```

**–ü–∞—Ç—á–∏:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224√ó224 ‚Üí –ø–∞—Ç—á–∏ 16√ó16 ‚Üí 14√ó14 = 196 –ø–∞—Ç—á–µ–π
–ö–∞–∂–¥—ã–π –ø–∞—Ç—á: 16√ó16√ó3 = 768 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç CNN –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –¢—Ä–µ–±—É–µ—Ç –æ–≥—Ä–æ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- –ë–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

### 5.8 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä

| –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ | –ì–æ–¥ | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | Top-1 Accuracy | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|-------------|-----|-----------|----------------|-------------|
| AlexNet | 2012 | 61M | 57% | –ü–µ—Ä–≤–∞—è –≥–ª—É–±–æ–∫–∞—è CNN |
| VGG-16 | 2014 | 138M | 71% | –ü—Ä–æ—Å—Ç—ã–µ 3√ó3 —Ñ–∏–ª—å—Ç—Ä—ã |
| GoogLeNet | 2014 | 7M | 74% | Inception –º–æ–¥—É–ª–∏ |
| ResNet-50 | 2015 | 26M | 76% | Residual connections |
| MobileNet | 2017 | 4M | 71% | –î–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö |
| EfficientNet-B7 | 2019 | 66M | 84% | Compound scaling |
| ViT-L | 2020 | 307M | 88% | Transformers |

---

## 6. –û–±—É—á–µ–Ω–∏–µ CNN

### 6.1 Loss Functions (–§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å)

#### Binary Cross-Entropy (2 –∫–ª–∞—Å—Å–∞)
```
L = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- Sigmoid –∞–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–∞ –≤—ã—Ö–æ–¥–µ

#### Categorical Cross-Entropy (–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–æ–≤)
```
L = -Œ£·µ¢ y·µ¢¬∑log(≈∑·µ¢)
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
- Softmax –∞–∫—Ç–∏–≤–∞—Ü–∏—è

#### Sparse Categorical Cross-Entropy
```
–¢–æ –∂–µ, —á—Ç–æ Categorical, –Ω–æ –º–µ—Ç–∫–∏ –≤ –≤–∏–¥–µ –∏–Ω–¥–µ–∫—Å–æ–≤ (–Ω–µ one-hot)
```

#### Mean Squared Error (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
```
L = (1/n)Œ£(y·µ¢ - ≈∑·µ¢)¬≤
```

### 6.2 –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã

#### SGD (Stochastic Gradient Descent)
```
W := W - Œ∑¬∑‚àáL
```

**–° Momentum:**
```
v := Œ≤¬∑v + ‚àáL
W := W - Œ∑¬∑v
```

**–° Nesterov:**
```
v := Œ≤¬∑v + ‚àáL(W - Œ≤¬∑v)
W := W - Œ∑¬∑v
```

#### Adam (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)
```
m := Œ≤‚ÇÅ¬∑m + (1-Œ≤‚ÇÅ)¬∑‚àáL         # –ø–µ—Ä–≤—ã–π –º–æ–º–µ–Ω—Ç
v := Œ≤‚ÇÇ¬∑v + (1-Œ≤‚ÇÇ)¬∑(‚àáL)¬≤      # –≤—Ç–æ—Ä–æ–π –º–æ–º–µ–Ω—Ç
mÃÇ := m / (1-Œ≤‚ÇÅ·µó)              # bias correction
vÃÇ := v / (1-Œ≤‚ÇÇ·µó)
W := W - Œ∑¬∑mÃÇ / (‚àövÃÇ + Œµ)
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- Œ≤‚ÇÅ = 0.9
- Œ≤‚ÇÇ = 0.999
- Œµ = 1e-8
- Œ∑ = 0.001 (—Ç–∏–ø–∏—á–Ω—ã–π learning rate)

#### RMSprop
```
v := Œ≤¬∑v + (1-Œ≤)¬∑(‚àáL)¬≤
W := W - Œ∑¬∑‚àáL / (‚àöv + Œµ)
```

### 6.3 Learning Rate Scheduling

**–ü—Ä–æ–±–ª–µ–º–∞:** —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LR –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º

**–°—Ç—Ä–∞—Ç–µ–≥–∏–∏:**

#### Step Decay
```
Œ∑ = Œ∑‚ÇÄ √ó Œ≥^(epoch / step_size)
```
–£–º–µ–Ω—å—à–∞—Ç—å –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö

#### Exponential Decay
```
Œ∑ = Œ∑‚ÇÄ √ó e^(-k¬∑epoch)
```

#### ReduceLROnPlateau
```
–ï—Å–ª–∏ val_loss –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è N —ç–ø–æ—Ö:
    Œ∑ := Œ∑ √ó factor
```

#### Cosine Annealing
```
Œ∑ = Œ∑_min + 0.5(Œ∑_max - Œ∑_min)(1 + cos(œÄT/T_max))
```

**–ü—Ä–∏–º–µ—Ä:**
```python
from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,       # Œ∑_new = Œ∑_old √ó 0.5
    patience=5,
    min_lr=1e-7
)
```

### 6.4 Data Augmentation

**–¶–µ–ª—å:** —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Üí —É–º–µ–Ω—å—à–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

**–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:**

#### –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ
- **Flip (–æ—Ç—Ä–∞–∂–µ–Ω–∏–µ):** horizontal, vertical
- **Rotation (–ø–æ–≤–æ—Ä–æ—Ç):** ¬±15¬∞, ¬±30¬∞
- **Shift (—Å–¥–≤–∏–≥):** ¬±10%, ¬±20%
- **Zoom (–º–∞—Å—à—Ç–∞–±):** 0.8-1.2√ó
- **Shear (—Å–¥–≤–∏–≥):** –Ω–µ–±–æ–ª—å—à–∞—è –¥–µ—Ñ–æ—Ä–º–∞—Ü–∏—è

#### –¶–≤–µ—Ç–æ–≤—ã–µ
- **Brightness (—è—Ä–∫–æ—Å—Ç—å):** ¬±20%
- **Contrast (–∫–æ–Ω—Ç—Ä–∞—Å—Ç):** 0.8-1.2√ó
- **Saturation (–Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å):** ¬±20%
- **Hue (–æ—Ç—Ç–µ–Ω–æ–∫):** ¬±10¬∞

#### –î—Ä—É–≥–∏–µ
- **Gaussian Noise:** –¥–æ–±–∞–≤–∏—Ç—å —à—É–º
- **Blur:** —Ä–∞–∑–º—ã—Ç–∏–µ
- **Cutout/Random Erasing:** —Å–ª—É—á–∞–π–Ω–æ —Å—Ç–µ—Ä–µ—Ç—å –æ–±–ª–∞—Å—Ç–∏
- **Mixup:** —Å–º–µ—à–∞—Ç—å –¥–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä –≤ Keras:**
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    shear_range=0.2,
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_directory(
    'train/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
```

### 6.5 Regularization

#### L2 Regularization (Weight Decay)
```
L_total = L + Œª¬∑Œ£w¬≤
```

```python
from tensorflow.keras.regularizers import l2

Conv2D(64, (3,3), kernel_regularizer=l2(0.01))
```

#### Dropout
```python
Dense(512) ‚Üí Dropout(0.5) ‚Üí Dense(num_classes)
```

#### Batch Normalization
```python
Conv2D(64, (3,3)) ‚Üí BatchNormalization() ‚Üí Activation('relu')
```

#### Early Stopping
```python
from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
```

### 6.6 Gradient Issues

#### Vanishing Gradients
**–ü—Ä–∏—á–∏–Ω—ã:**
- –ú–Ω–æ–≥–æ —Å–ª–æ–µ–≤
- Sigmoid/tanh –∞–∫—Ç–∏–≤–∞—Ü–∏–∏

**–†–µ—à–µ–Ω–∏—è:**
- ReLU –∞–∫—Ç–∏–≤–∞—Ü–∏—è
- Batch Normalization
- Residual connections (ResNet)
- –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (He, Xavier)

#### Exploding Gradients
**–ü—Ä–∏—á–∏–Ω—ã:**
- –ë–æ–ª—å—à–∏–µ –≤–µ—Å–∞
- –ú–Ω–æ–≥–æ —Å–ª–æ–µ–≤

**–†–µ—à–µ–Ω–∏—è:**
- Gradient Clipping
- Batch Normalization
- –£–º–µ–Ω—å—à–∏—Ç—å learning rate

---

## 7. Transfer Learning

### 7.1 –ß—Ç–æ —Ç–∞–∫–æ–µ Transfer Learning?

**–ò–¥–µ—è:** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–Ω–∞ –±–æ–ª—å—à–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ) –¥–ª—è —Å–≤–æ–µ–π –∑–∞–¥–∞—á–∏

**–ú–æ—Ç–∏–≤–∞—Ü–∏—è:**
- –û–±—É—á–µ–Ω–∏–µ CNN —Å –Ω—É–ª—è —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –∏ –≤—Ä–µ–º–µ–Ω–∏
- –ù–∏–∑–∫–∏–µ —Å–ª–æ–∏ —É—á–∞—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫—Ä–∞—è, —Ç–µ–∫—Å—Ç—É—Ä—ã)
- –í—ã—Å–æ–∫–∏–µ —Å–ª–æ–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã –¥–ª—è –∑–∞–¥–∞—á–∏

### 7.2 –ü–æ–¥—Ö–æ–¥—ã

#### Feature Extraction (–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
```
–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è CNN ‚Üí [–ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤–µ—Å–∞] ‚Üí –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ FC —Å–ª–æ–∏
```

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è)
2. –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤—Å–µ –≤–µ—Å–∞ (trainable=False)
3. –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ Dense —Å–ª–æ–∏ –¥–ª—è —Å–≤–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤
4. –û–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–ª–æ–∏

**–ü—Ä–∏–º–µ—Ä:**
```python
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
base_model = ResNet50(weights='imagenet', include_top=False, 
                      input_shape=(224, 224, 3))

# –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤–µ—Å–∞
base_model.trainable = False

# –î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–∏ —Å–ª–æ–∏
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

# –ö–æ–º–ø–∏–ª—è—Ü–∏—è
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
```

#### Fine-Tuning (–¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
```
–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è CNN ‚Üí [–†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å —á–∞—Å—Ç—å —Å–ª–æ–µ–≤] ‚Üí –î–æ–æ–±—É—á–∏—Ç—å
```

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. –ù–∞—á–∞—Ç—å —Å Feature Extraction
2. –û–±—É—á–∏—Ç—å –Ω–æ–≤—ã–µ —Å–ª–æ–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö)
3. –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–ª–æ–µ–≤ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
4. –î–æ–æ–±—É—á–∏—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º learning rate

**–ü—Ä–∏–º–µ—Ä:**
```python
# –°–Ω–∞—á–∞–ª–∞ Feature Extraction
model.fit(train_data, epochs=10)

# –¢–µ–ø–µ—Ä—å Fine-Tuning
# –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–ª–æ–µ–≤
for layer in base_model.layers[-20:]:
    layer.trainable = True

# –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º LR
model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# –î–æ–æ–±—É—á–∏—Ç—å
model.fit(train_data, epochs=20)
```

### 7.3 –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?

**–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:**

| –î–∞—Ç–∞—Å–µ—Ç | –ü–æ—Ö–æ–∂ –Ω–∞ ImageNet | –û—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç ImageNet |
|---------|-------------------|------------------------|
| –ú–∞–ª–µ–Ω—å–∫–∏–π (<1k) | Feature Extraction | Feature Extraction + Fine-tune –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ–µ–≤ |
| –°—Ä–µ–¥–Ω–∏–π (1k-100k) | Fine-Tuning | Feature Extraction + –æ–±—É—á–∏—Ç—å –±–æ–ª—å—à–µ —Å–ª–æ–µ–≤ |
| –ë–æ–ª—å—à–æ–π (>100k) | Fine-Tuning –∏–ª–∏ —Å –Ω—É–ª—è | –û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è |

### 7.4 –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏

**ImageNet:**
- ResNet50, ResNet101
- VGG16, VGG19
- InceptionV3, InceptionResNetV2
- MobileNetV2
- EfficientNet-B0 –¥–æ B7

**–ó–∞–≥—Ä—É–∑–∫–∞ –≤ Keras:**
```python
from tensorflow.keras.applications import (
    ResNet50, VGG16, InceptionV3, MobileNetV2, EfficientNetB0
)

model = ResNet50(weights='imagenet', include_top=False)
```

---

## 8. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ CNN

### 8.1 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**–ó–∞–¥–∞—á–∞:** –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–ª–∞—Å—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä—ã:**
- –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ü–∏—Ñ—Ä (MNIST)
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∏–≤–æ—Ç–Ω—ã—Ö (cats vs dogs)
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (—Ä–µ–Ω—Ç–≥–µ–Ω—ã)
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤

**–î–∞—Ç–∞—Å–µ—Ç—ã:**
- MNIST: 60k —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä 28√ó28
- CIFAR-10: 60k –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π 32√ó32, 10 –∫–ª–∞—Å—Å–æ–≤
- ImageNet: 14M –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, 1000 –∫–ª–∞—Å—Å–æ–≤
- Fashion-MNIST: 60k –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–¥–µ–∂–¥—ã

### 8.2 Object Detection (–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤)

**–ó–∞–¥–∞—á–∞:** –Ω–∞–π—Ç–∏ –æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã

**–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–µ—Ç–æ–¥—ã:**
- **R-CNN, Fast R-CNN, Faster R-CNN**
- **YOLO (You Only Look Once)** ‚Äî real-time
- **SSD (Single Shot Detector)**
- **RetinaNet**

**–§–æ—Ä–º–∞—Ç:**
```
–í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
–í—ã—Ö–æ–¥: [(–∫–ª–∞—Å—Å, bbox, confidence), ...]
bbox = (x1, y1, x2, y2)
```

### 8.3 Semantic Segmentation

**–ó–∞–¥–∞—á–∞:** –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
- **FCN (Fully Convolutional Network)**
- **U-Net** ‚Äî –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- **DeepLab**
- **Mask R-CNN** ‚Äî instance segmentation

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –≤–æ–∂–¥–µ–Ω–∏–µ
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤

### 8.4 Face Recognition

**–ó–∞–¥–∞—á–∞:** –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è/–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –ª–∏—Ü–∞

**–ü–æ–¥—Ö–æ–¥:**
```
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí CNN ‚Üí Embedding (–≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: distance(embedding1, embedding2)
```

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
- **FaceNet** ‚Äî Triplet Loss
- **DeepFace** (Facebook)
- **ArcFace, CosFace**

### 8.5 Style Transfer

**–ó–∞–¥–∞—á–∞:** –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ —Å—Ç–∏–ª—å –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –¥—Ä—É–≥–æ–µ

**–ú–µ—Ç–æ–¥:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ–µ–≤ CNN
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- Artistic filters
- –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ñ–æ—Ç–æ

### 8.6 Image Generation

**GANs (Generative Adversarial Networks):**
```
Generator: —à—É–º ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
Discriminator: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí real/fake
```

**Diffusion Models:**
- Stable Diffusion
- DALL-E 2, Midjourney

---

## 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

### 9.1 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ CIFAR-10

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# One-hot encoding
y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)

print(f"Train: {X_train.shape}, Test: {X_test.shape}")

# 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.15, random_state=42
)

print(f"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")

# 3. Data Augmentation
train_datagen = keras.preprocessing.image.ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
train_datagen.fit(X_train)

# 4. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
def create_cnn_model():
    model = keras.Sequential([
        # Block 1
        layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.Conv2D(32, (3, 3), padding='same'),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        # Block 2
        layers.Conv2D(64, (3, 3), padding='same'),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.Conv2D(64, (3, 3), padding='same'),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),
        
        # Block 3
        layers.Conv2D(128, (3, 3), padding='same'),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.Conv2D(128, (3, 3), padding='same'),
        layers.BatchNormalization(),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.4),
        
        # Classification head
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(10, activation='softmax')
    ])
    
    return model

model = create_cnn_model()
model.summary()

# 5. –ö–æ–º–ø–∏–ª—è—Ü–∏—è
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 6. Callbacks
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True,
    verbose=1
)

checkpoint = ModelCheckpoint(
    'best_cifar10_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

# 7. –û–±—É—á–µ–Ω–∏–µ
history = model.fit(
    train_datagen.flow(X_train, y_train, batch_size=64),
    validation_data=(X_val, y_val),
    epochs=100,
    callbacks=[early_stop, checkpoint, reduce_lr],
    verbose=1
)

# 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)
axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Loss', fontsize=12)
axes[0].set_title('Loss vs Epoch', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Accuracy
axes[1].plot(history.history['accuracy'], label='Train Acc', linewidth=2)
axes[1].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Accuracy', fontsize=12)
axes[1].set_title('Accuracy vs Epoch', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_history_cifar10.png', dpi=300)
plt.show()

# 9. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\nTest Accuracy: {test_acc:.4f}")
print(f"Test Loss: {test_loss:.4f}")

# 10. Confusion Matrix
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_test_classes, y_pred_classes)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=range(10), yticklabels=range(10))
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('True', fontsize=12)
plt.title('Confusion Matrix - CIFAR-10', fontsize=14)
plt.savefig('confusion_matrix_cifar10.png', dpi=300)
plt.show()

# 11. Classification Report
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck']

print("\nClassification Report:")
print(classification_report(y_test_classes, y_pred_classes, 
                          target_names=classes))

# 12. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
def plot_predictions(X, y_true, y_pred, classes, n=10):
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    axes = axes.ravel()
    
    indices = np.random.choice(len(X), n, replace=False)
    
    for i, idx in enumerate(indices):
        axes[i].imshow(X[idx])
        axes[i].axis('off')
        
        true_label = classes[y_true[idx]]
        pred_label = classes[y_pred[idx]]
        confidence = np.max(y_pred[idx])
        
        color = 'green' if y_true[idx] == y_pred[idx] else 'red'
        axes[i].set_title(f'True: {true_label}\nPred: {pred_label}\n({confidence:.2f})',
                         fontsize=10, color=color)
    
    plt.tight_layout()
    plt.savefig('predictions_cifar10.png', dpi=300)
    plt.show()

plot_predictions(X_test, y_test_classes, y_pred_classes, classes)
```

### 9.2 Transfer Learning –ø—Ä–∏–º–µ—Ä

```python
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout

# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# 2. –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
base_model.trainable = False

# 3. –î–æ–±–∞–≤–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—É—é –≥–æ–ª–æ–≤—É
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

# 4. –ö–æ–º–ø–∏–ª—è—Ü–∏—è
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 5. –û–±—É—á–µ–Ω–∏–µ (Feature Extraction)
history1 = model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,
    callbacks=[early_stop, checkpoint]
)

# 6. Fine-Tuning
# –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–ª–æ–µ–≤
base_model.trainable = True
for layer in base_model.layers[:-20]:
    layer.trainable = False

# –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å —Å –º–∞–ª–µ–Ω—å–∫–∏–º LR
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# –î–æ–æ–±—É—á–∏—Ç—å
history2 = model.fit(
    train_data,
    validation_data=val_data,
    epochs=20,
    callbacks=[early_stop, checkpoint, reduce_lr]
)
```

---

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

**–û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã:**

1. **CNN** ‚Äî –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è
2. **–°–≤–µ—Ä—Ç–∫–∞** ‚Äî –∫–ª—é—á–µ–≤–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
3. **–ì–ª—É–±–æ–∫–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã** (ResNet, EfficientNet) –¥–∞—é—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
4. **Transfer Learning** —ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è –∏ –¥–∞–Ω–Ω—ã–µ
5. **Data Augmentation** –∫—Ä–∏—Ç–∏—á–Ω–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**

1. –ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä (3-4 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–∞)
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Batch Normalization –∏ Dropout
3. –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ Data Augmentation
4. –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ ‚Äî Transfer Learning
5. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
6. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

**–î–∞–ª—å–Ω–µ–π—à–µ–µ –∏–∑—É—á–µ–Ω–∏–µ:**
- Object Detection (YOLO, Faster R-CNN)
- Semantic Segmentation (U-Net)
- GANs –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- Vision Transformers
- Neural Architecture Search
